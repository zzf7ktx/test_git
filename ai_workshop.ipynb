{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzf7ktx/test_git/blob/main/ai_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3vPQolzXuic"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "collapsed": true,
        "id": "mid0pqKuWYOP"
      },
      "outputs": [],
      "source": [
        "data_url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "data_url_1 = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "f4Rh6a2Vnz8V"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MovieLens1m:\n",
        "  def __init__(self, url: str):\n",
        "    self.url = url\n",
        "    self.__download()\n",
        "    self.__read_users()\n",
        "    self.__read_movies()\n",
        "    self.__read_ratings()\n",
        "    !rm ml-1m.zip\n",
        "    !rm -rf ml-1m\n",
        "\n",
        "  def __download(self):\n",
        "    print('Downloading')\n",
        "    zip_path = 'ml-1m.zip'\n",
        "    !wget {self.url} -O {zip_path}\n",
        "\n",
        "    print('Extracting')\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "    self.base_path = 'ml-1m'\n",
        "\n",
        "  def __read_ratings(self, filename='ratings.dat'):\n",
        "    print('Reading ratings')\n",
        "    headers = ['u_nodes', 'v_nodes', 'ratings', 'timestamp']\n",
        "    dtypes = {\n",
        "      'u_nodes': np.int64, 'v_nodes': np.int64,\n",
        "      'ratings': np.float32, 'timestamp': np.float64\n",
        "    }\n",
        "    sep = r'\\:\\:'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.ratings_df = pd.read_csv(file_path, sep=sep, header=None,\n",
        "                       names=headers,\n",
        "                       converters=dtypes, engine='python',\n",
        "                       encoding='latin-1')\n",
        "\n",
        "  def __read_users(self, filename='users.dat'):\n",
        "    print('Reading users')\n",
        "    headers = ['user_id', 'gender', 'age', 'occupation', 'zip-code']\n",
        "    sep = r'\\:\\:'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.users_df = pd.read_csv(file_path, sep=sep,header = None,\n",
        "                       names = headers, engine= 'python',\n",
        "                       encoding='latin-1')\n",
        "\n",
        "  def __read_movies(self, filename='movies.dat'):\n",
        "    print('Reading movies')\n",
        "    headers = ['movie_id', 'title', 'genre']\n",
        "    sep = r'\\:\\:'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.movies_df = pd.read_csv(file_path, sep=sep,header = None,\n",
        "                       names = headers, engine= 'python',\n",
        "                       encoding='latin-1')\n",
        "\n",
        "class MovieLens100k:\n",
        "  def __init__(self, url: str):\n",
        "    self.url = url\n",
        "    self.__download()\n",
        "    self.__read_users()\n",
        "    self.__read_movies()\n",
        "    self.__read_ratings()\n",
        "    !rm ml-100k.zip\n",
        "    !rm -rf ml-100k\n",
        "\n",
        "  def __download(self):\n",
        "    print('Downloading')\n",
        "    zip_path = 'ml-100k.zip'\n",
        "    !wget {self.url} -O {zip_path}\n",
        "\n",
        "    print('Extracting')\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "    self.base_path = 'ml-100k'\n",
        "\n",
        "  def __read_ratings(self, filename='u.data'):\n",
        "    print('Reading ratings')\n",
        "    headers = ['u_nodes', 'v_nodes', 'ratings', 'timestamp']\n",
        "    dtypes = {\n",
        "      'u_nodes': np.int64, 'v_nodes': np.int64,\n",
        "      'ratings': np.float32, 'timestamp': np.float64\n",
        "    }\n",
        "    sep = r'\\t'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.ratings_df = pd.read_csv(file_path, sep=sep, header=None,\n",
        "                       names=headers,\n",
        "                       converters=dtypes, engine='python',\n",
        "                       encoding='latin-1')\n",
        "\n",
        "  def __read_users(self, filename='u.user'):\n",
        "    print('Reading users')\n",
        "    headers = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
        "    sep = r'|'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.users_df = pd.read_csv(file_path, sep=sep,header = None,\n",
        "                       names = headers, engine= 'python',\n",
        "                       encoding='latin-1')\n",
        "\n",
        "  def __read_movies(self, filename='u.item'):\n",
        "    print('Reading movies')\n",
        "    headers = ['movie id', 'movie title', 'release date', 'video release date',\n",
        "               'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "               'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "               'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
        "               'Thriller', 'War', 'Western']\n",
        "    sep = r'|'\n",
        "    file_path = self.base_path + '/' + filename\n",
        "    self.movies_df = pd.read_csv(file_path, sep=sep,header = None,\n",
        "                       names = headers, engine= 'python',\n",
        "                       encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oMyLRnzeBjZ",
        "outputId": "6cd52a3a-bad9-4842-9251-574c62f2617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading\n",
            "--2025-07-08 07:53:00--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  3.20MB/s    in 1.5s    \n",
            "\n",
            "2025-07-08 07:53:02 (3.20 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Extracting\n",
            "Reading users\n",
            "Reading movies\n",
            "Reading ratings\n"
          ]
        }
      ],
      "source": [
        "dataset = MovieLens100k(data_url_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-NB-m6-pZJ6"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7HAmjzZsY5p"
      },
      "source": [
        "## IGMC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install"
      ],
      "metadata": {
        "id": "I7IDBd9V--Dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KgCoNBl-twcG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0tS5vjA9sbQd"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os, sys, pdb, math, time\n",
        "from copy import deepcopy\n",
        "import multiprocessing as mp\n",
        "import networkx as nx\n",
        "import argparse\n",
        "import scipy.io as sio\n",
        "import scipy.sparse as ssp\n",
        "import torch\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "import pickle as pkl\n",
        "import scipy.sparse as sp\n",
        "from torch_geometric.data import DataLoader\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ukiXiawT_ET"
      },
      "source": [
        "### Construct data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "Nufpi7CWuYyG"
      },
      "outputs": [],
      "source": [
        "def subgraph_extraction_labeling(ind, Arow, Acol, h=1, sample_ratio=1.0,\n",
        "                                 max_nodes_per_hop = None, u_features = None,\n",
        "                                 v_features = None, class_values = None, y =1):\n",
        "  # extract the h-hop enclosing subgraph around link 'ind'\n",
        "  u_nodes, v_nodes = [ind[0]], [ind[1]]\n",
        "  u_dist, v_dist = [0], [0]\n",
        "  u_visited, v_visited = set([ind[0]]), set([ind[1]])\n",
        "  u_fringe, v_fringe = set([ind[0]]), set([ind[1]])\n",
        "  for dist in range(1, h+1):\n",
        "    v_fringe, u_fringe = neighbors(u_fringe, Arow), neighbors(v_fringe, Acol)\n",
        "    u_fringe = u_fringe - u_visited\n",
        "    v_fringe = v_fringe - v_visited\n",
        "    u_visited = u_visited.union(u_fringe)\n",
        "    v_visited = v_visited.union(v_fringe)\n",
        "    if sample_ratio < 1.0:\n",
        "      u_fringe = random.sample(list(u_fringe), int(sample_ratio*len(u_fringe)))\n",
        "      v_fringe = random.sample(list(v_fringe), int(sample_ratio*len(v_fringe)))\n",
        "    if max_nodes_per_hop is not None:\n",
        "      if max_nodes_per_hop < len(u_fringe):\n",
        "        u_fringe = random.sample(list(u_fringe), max_nodes_per_hop)\n",
        "      if max_nodes_per_hop < len(v_fringe):\n",
        "        v_fringe = random.sample(list(v_fringe), max_nodes_per_hop)\n",
        "    if len(u_fringe)  == 0 and len(v_fringe) == 0:\n",
        "      break\n",
        "\n",
        "    u_nodes = u_nodes + list(u_fringe)\n",
        "    v_nodes = v_nodes + list(v_fringe)\n",
        "    u_dist = u_dist + [dist]*len(u_fringe)\n",
        "    v_dist = v_dist + [dist]*len(v_fringe)\n",
        "\n",
        "  subgraph = Arow[u_nodes][:, v_nodes]\n",
        "  # remove link between target nodes\n",
        "  subgraph[0, 0] = 0\n",
        "\n",
        "  # prepare pyg graph constructor input\n",
        "  u, v, r = ssp.find(subgraph) #r is 1, 2,... (rating labels + 1)\n",
        "  v += len(u_nodes)\n",
        "  r = r - 1 # transform r back to rating label\n",
        "  num_nodes = len(u_nodes) + len(v_nodes)\n",
        "  node_labels = [x*2 for x in u_dist] + [x*2+1 for x in v_dist]\n",
        "  max_node_label = 2*h + 1\n",
        "  y = class_values[y]\n",
        "\n",
        "  # get node features\n",
        "  if u_features is not None:\n",
        "    u_features = u_features[u_nodes]\n",
        "  if v_features is not None:\n",
        "    v_features = v_features[v_nodes]\n",
        "  node_features = None\n",
        "  if False:\n",
        "    # directly use padded node features\n",
        "    if u_features is not None and v_features is not None:\n",
        "      u_extended = np.concatenate(\n",
        "          [u_features, np.zeros([u_features.shape[0], v_features.shape[1]])], 1\n",
        "      )\n",
        "      v_extended = np.concatenate(\n",
        "          [np.zeros([v_features.shape[0], u_features.shape[1]]), v_features], 1\n",
        "      )\n",
        "      node_features = np.concatenate([u_extended, v_extended], 0)\n",
        "  if False:\n",
        "    # use identity features (one-hot encodings of node idxes)\n",
        "    u_ids = one_hot(u_nodes, Arow.shape[0] + Arow.shape[1])\n",
        "    v_ids = one_hot([x+Arow.shape[0] for x in v_nodes], Arow.shape[0] + Arow.shape[1])\n",
        "\n",
        "    node_ids = np.concatenate([u_ids, v_ids], 0)\n",
        "    # node_features = np.concatenate([node_features, node_ids], 1)\n",
        "    node_features = node_ids\n",
        "\n",
        "  if True:\n",
        "    # only output node features for the target user and item\n",
        "    if u_features is not None and v_features is not None:\n",
        "      # Convert sparse matrices to dense NumPy arrays before returning\n",
        "      node_features = [u_features[0].todense(), v_features[0].todense()]\n",
        "\n",
        "  return u, v, r, node_labels, max_node_label, y, node_features\n",
        "\n",
        "def construct_pyg_graph(u, v, r, node_labels, max_node_label, y, node_features):\n",
        "  u, v = torch.LongTensor(u), torch.LongTensor(v)\n",
        "  r = torch.LongTensor(r)\n",
        "  edge_index = torch.stack([torch.cat([u, v]), torch.cat([v, u])], 0)\n",
        "  edge_type = torch.cat([r, r])\n",
        "  x = torch.FloatTensor(one_hot(node_labels, max_node_label+1))\n",
        "  y = torch.FloatTensor([y])\n",
        "  data = Data(x, edge_index, edge_type = edge_type, y = y)\n",
        "\n",
        "  if node_features is not None:\n",
        "    if type(node_features) == list:\n",
        "      u_feature, v_feature = node_features\n",
        "      data.u_feature = torch.FloatTensor(u_feature).unsqueeze(0)\n",
        "      data.v_feature = torch.FloatTensor(v_feature).unsqueeze(0)\n",
        "    else:\n",
        "      x2 = torch.FloatTensor(node_features)\n",
        "      data.x = torch.cat([data.x, x2], 1)\n",
        "  return data\n",
        "\n",
        "def neighbors(fringe, A):\n",
        "  # find all 1-hop neighbors of nodes in fringe from A\n",
        "  return set(A[list(fringe)].indices)\n",
        "\n",
        "def one_hot(idx, length):\n",
        "  idx = np.array(idx)\n",
        "  x = np.zeros([len(idx), length])\n",
        "  x[np.arange(len(idx)), idx] = 1.0\n",
        "  return x\n",
        "\n",
        "class SparseRowIndexer:\n",
        "  def __init__(self, csr_matrix):\n",
        "    data = []\n",
        "    indices = []\n",
        "    indptr = []\n",
        "\n",
        "    for row_start, row_end in zip(csr_matrix.indptr[:-1], csr_matrix.indptr[1:]):\n",
        "      data.append(csr_matrix.data[row_start:row_end])\n",
        "      indices.append(csr_matrix.indices[row_start:row_end])\n",
        "      indptr.append(row_end - row_start)  #nnz of the row\n",
        "\n",
        "    self.data = np.array(data, dtype = object)\n",
        "    self.indices = np.array(indices, dtype = object)\n",
        "    self.indptr = np.array(indptr, dtype = object)\n",
        "    self.shape = csr_matrix.shape\n",
        "  def __getitem__(self, row_selector):\n",
        "    indices = np.concatenate(self.indices[row_selector])\n",
        "    data = np.concatenate(self.data[row_selector])\n",
        "    indptr = np.append(0, np.cumsum(self.indptr[row_selector]))\n",
        "    shape = [indptr.shape[0] - 1, self.shape[1]]\n",
        "    return ssp.csr_matrix((data, indices, indptr), shape = shape)\n",
        "\n",
        "class SparseColIndexer:\n",
        "  def __init__(self, csc_matrix):\n",
        "    data = []\n",
        "    indices = []\n",
        "    indptr = []\n",
        "\n",
        "    for col_start, col_end in zip(csc_matrix.indptr[:-1], csc_matrix.indptr[1:]):\n",
        "      data.append(csc_matrix.data[col_start:col_end])\n",
        "      indices.append(csc_matrix.data[col_start:col_end])\n",
        "      indptr.append(col_end - col_start)\n",
        "\n",
        "    self.data = np.array(data, dtype = object)\n",
        "    self.indices = np.array(indices, dtype = object)\n",
        "    self.indptr = np.array(indptr, dtype = object)\n",
        "    self.shape = csc_matrix.shape\n",
        "\n",
        "  def __getitem__(self, col_selector):\n",
        "    indices = np.concatenate(self.indices[col_selector])\n",
        "    data = np.concatenate(self.data[col_selector])\n",
        "    indptr = np.append(0, np.cumsum(self.indptr[col_selector]))\n",
        "\n",
        "    shape = [self.shape[0], indptr.shape[0] - 1]\n",
        "    return ssp.csc_matrix((data, indices, indptr), shape = shape)\n",
        "\n",
        "\n",
        "def links2subgraphs(Arow, Acol, links, labels, h=1, sample_ratio = 1.0,\n",
        "                    max_nodes_per_hop = None, u_features = None, v_features = None,\n",
        "                    class_values = None, parallel = True):\n",
        "  # Extract enclosing subgraphs\n",
        "  print('Enclosing subgraph extraction begins...')\n",
        "  g_list = []\n",
        "  if not parallel:\n",
        "    with tqdm(total = len(links[0])) as pbar:\n",
        "      for i, j, g_label in zip(links[0], links[1], labels):\n",
        "        tmp = subgraph_extraction_labeling((i, j), Arow, Acol, h, sample_ratio,\n",
        "                                           max_nodes_per_hop, u_features, v_features,\n",
        "                                           class_values, g_label)\n",
        "        data = construct_pyg_graph(*tmp)\n",
        "        g_list.append(data)\n",
        "        pbar.update(1)\n",
        "  else:\n",
        "    start = time.time()\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    results = pool.starmap_async(\n",
        "        subgraph_extraction_labeling,\n",
        "        [\n",
        "         ((i,j), Arow, Acol, h, sample_ratio, max_nodes_per_hop, u_features,\n",
        "          v_features, class_values, g_label)\n",
        "         for i, j, g_label in zip(links[0], links[1], labels)\n",
        "        ]\n",
        "    )\n",
        "    remaining = results._number_left\n",
        "    pbar = tqdm(total = remaining)\n",
        "    while True:\n",
        "      pbar.update(remaining - results._number_left)\n",
        "      if results.ready(): break\n",
        "      remaining = results._number_left\n",
        "      time.sleep(1)\n",
        "    results = results.get()\n",
        "    pool.close()\n",
        "    pbar.close()\n",
        "    end = time.time()\n",
        "    print(\"Time elapsed for subgraph extraction: {}s\".format(end-start))\n",
        "    print(\"Tranforming to pytorch_geometric graphs...\")\n",
        "    g_list = []\n",
        "    pbar = tqdm(total = len(results))\n",
        "    while results:\n",
        "      tmp = results.pop()\n",
        "      g_list.append(construct_pyg_graph(*tmp))\n",
        "      pbar.update(1)\n",
        "    pbar.close()\n",
        "    end2 = time.time()\n",
        "    print(\"Time elapsed for transforming to pytorch_geometric graphs: {}s\".format(end2-end))\n",
        "  return g_list\n",
        "\n",
        "class MyDataset(InMemoryDataset):\n",
        "  def __init__(self, root, A, links, labels, h, sample_ratio, max_nodes_per_hop,\n",
        "               u_features, v_features, class_values, max_num = None, parallel=True):\n",
        "    self.Arow = SparseRowIndexer(A)\n",
        "    self.Acol = SparseColIndexer(A.tocsc())\n",
        "    self.links = links\n",
        "    self.labels = labels\n",
        "    self.h = h\n",
        "    self.sample_ratio = sample_ratio\n",
        "    self.max_nodes_per_hop = max_nodes_per_hop\n",
        "    self.u_features = u_features\n",
        "    self.v_features = v_features\n",
        "    self.class_values = class_values\n",
        "    self.parallel = parallel\n",
        "    self.max_num = max_num\n",
        "    if max_num is not None:\n",
        "      np.random.seed(123)\n",
        "      num_links = len(links[0])\n",
        "      perm = np.random.permutation(num_links)\n",
        "      perm = perm[:max_num]\n",
        "      self.links = (links[0][perm], links[1][perm])\n",
        "      self.labels = labels[perm]\n",
        "    super(MyDataset, self).__init__(root)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    name = 'data.pt'\n",
        "    if self.max_num is not None:\n",
        "      name = 'data_{}.pt'.format(self.max_num)\n",
        "    return [name]\n",
        "\n",
        "  def process(self):\n",
        "    # Extract enclosing subgraphs and save to disk\n",
        "    data_list = links2subgraphs(self.Arow, self.Acol, self.links, self.labels, self.h,\n",
        "                                self.sample_ratio, self.max_nodes_per_hop,\n",
        "                                self.u_features, self.v_features,\n",
        "                                self.class_values, self.parallel)\n",
        "\n",
        "    data, slices = self.collate(data_list)\n",
        "    torch.save((data, slices), self.processed_paths[0])\n",
        "    del data_list\n",
        "\n",
        "class MyDynamicDataset(Dataset):\n",
        "  def __init__(self, root, A, links, labels, h, sample_ratio, max_nodes_per_hop,\n",
        "                u_features, v_features, class_values, max_num=None):\n",
        "    super(MyDynamicDataset, self).__init__(root)\n",
        "    self.Arow = SparseRowIndexer(A)\n",
        "    self.Acol = SparseColIndexer(A.tocsc())\n",
        "    self.links = links\n",
        "    self.labels = labels\n",
        "    self.h = h\n",
        "    self.sample_ratio = sample_ratio\n",
        "    self.max_nodes_per_hop = max_nodes_per_hop\n",
        "    self.u_features = u_features\n",
        "    self.v_features = v_features\n",
        "    self.class_values = class_values\n",
        "    if max_num is not None:\n",
        "      np.random.seed(123)\n",
        "      num_links = len(links[0])\n",
        "      perm = np.random.permutation(num_links)\n",
        "      perm = perm[:max_num]\n",
        "      self.links = (links[0][perm], links[1][perm])\n",
        "      self.labels = labels[perm]\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.links[0])\n",
        "\n",
        "  def get(self, idx):\n",
        "    i, j = self.links[0][idx], self.links[1][idx]\n",
        "    g_label = self.labels[idx]\n",
        "    tmp = subgraph_extraction_labeling(\n",
        "      (i, j), self.Arow, self.Acol, self.h, self.sample_ratio, self.max_nodes_per_hop,\n",
        "      self.u_features, self.v_features, self.class_values, g_label\n",
        "    )\n",
        "    return construct_pyg_graph(*tmp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZymfJsCUu_x"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "sexFGV84xWQH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Conv1d\n",
        "from torch_geometric.nn import GCNConv, RGCNConv, global_sort_pool, global_add_pool\n",
        "from torch_geometric.utils import dropout_adj\n",
        "import pdb\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "  # a base GNN class, GCN message passing + sum_pooling\n",
        "  def __init__(self, dataset, gconv = GCNConv, latent_dim=[32, 32, 32, 1],\n",
        "               regression = False, adj_dropout = 0.2,\n",
        "               force_undirected = False):\n",
        "    super(GNN, self).__init__()\n",
        "    self.regression = regression\n",
        "    self.adj_dropout = adj_dropout\n",
        "    self.force_undirected = force_undirected\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(gconv(4, latent_dim[0]))\n",
        "    for i in range(0, len(latent_dim)-1):\n",
        "      self.convs.append(gconv(latent_dim[i], latent_dim[i+1]))\n",
        "    self.lin1 = Linear(sum(latent_dim), 128)\n",
        "    if self.regression:\n",
        "      self.lin2 = Linear(128, 1)\n",
        "    else:\n",
        "      self.lin2 = Linear(128, dataset.num_classes)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "    self.lin1.reset_parameters()\n",
        "    self.lin2.reset_parameters()\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "    if self.adj_dropout > 0:\n",
        "      edge_index, edge_type = dropout_adj(edge_index, edge_type, p=self.adj_dropout,\n",
        "                                          force_undirected=self.force_undirected,\n",
        "                                          num_nodes=len(x), training=self.training\n",
        "        )\n",
        "    concat_states = []\n",
        "    for conv in self.convs:\n",
        "      x = torch.tanh(conv(x, edge_index))\n",
        "      concat_states.append(x)\n",
        "    concat_states = torch.cat(concat_states, 1)\n",
        "    x = global_add_pool(concat_states, batch)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.lin2(x)\n",
        "    if self.regression:\n",
        "      return x[:, 0]\n",
        "    else:\n",
        "      return F.log_softmax(x, dim=-1)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__\n",
        "\n",
        "class IGMC(GNN):\n",
        "  # The GNN model of Inductive Graph-based Matrix Completion.\n",
        "  # Use RGCN convolution + center-nodes readout.\n",
        "  def __init__(self, dataset, gconv=RGCNConv, latent_dim=[32, 32, 32, 32],\n",
        "               num_relations=5, num_bases=2, regression=False, adj_dropout=0.2,\n",
        "               force_undirected=False, side_features=False, n_side_features=0,\n",
        "               multiply_by=1):\n",
        "    super(IGMC, self).__init__(dataset, GCNConv, latent_dim,\n",
        "                               regression, adj_dropout, force_undirected\n",
        "    )\n",
        "    self.multiply_by = multiply_by\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(gconv(4, latent_dim[0], num_relations, num_bases))\n",
        "    for i in range(0, len(latent_dim)-1):\n",
        "      self.convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases))\n",
        "    self.lin1 = Linear(2*sum(latent_dim), 128)\n",
        "    self.side_features = side_features\n",
        "    if side_features:\n",
        "      self.lin1 = Linear(2*sum(latent_dim)+n_side_features, 128)\n",
        "\n",
        "  def forward(self, data):\n",
        "    start = time.time()\n",
        "    x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n",
        "    if self.adj_dropout > 0:\n",
        "      edge_index, edge_mask = dropout_edge(edge_index, p=self.adj_dropout,\n",
        "                                           force_undirected=self.force_undirected,\n",
        "                                           training=self.training)\n",
        "      edge_type = data.edge_type[edge_mask]\n",
        "    concat_states = []\n",
        "    for conv in self.convs:\n",
        "      x = torch.tanh(conv(x, edge_index, edge_type))\n",
        "      concat_states.append(x)\n",
        "    concat_states = torch.cat(concat_states, 1)\n",
        "\n",
        "    users = data.x[:, 0] == 1\n",
        "    items = data.x[:, 1] == 1\n",
        "    x = torch.cat([concat_states[users], concat_states[items]], 1)\n",
        "    if self.side_features:\n",
        "      x = torch.cat([x, data.u_feature, data.v_feature], 1)\n",
        "\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.lin2(x)\n",
        "    if self.regression:\n",
        "      return x[:, 0] * self.multiply_by\n",
        "    else:\n",
        "      return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4tRhhVAUFbG"
      },
      "source": [
        "### Training utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_7AAKlC_wSd8"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.optim import Adam\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "Yk__yCPAwg9W"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loader, device, regression = False, ARR = 0, show_progress= False, epoch = None):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  if show_progress:\n",
        "    pbar = tqdm(loader)\n",
        "  else:\n",
        "    pbar = loader\n",
        "  for data in pbar:\n",
        "    optimizer.zero_grad()\n",
        "    data = data.to(device)\n",
        "    out = model(data)\n",
        "    if regression:\n",
        "      loss = F.mse_loss(out, data.y.view(-1))\n",
        "    else:\n",
        "      loss = F.nll_loss(out, data.y.view(-1))\n",
        "    if show_progress:\n",
        "      pbar.set_description('Epoch {}, batch loss: {}'.format(epoch, loss.item()))\n",
        "    if ARR != 0:\n",
        "      for gconv in model.convs:\n",
        "        w = torch.matmul(gconv.comp,\n",
        "                         gconv.weight.view(gconv.num_bases, -1)\n",
        "        ).view(gconv.num_relations, gconv.in_channels, gconv.out_channels)\n",
        "        reg_loss = torch.sum((w[1:, :, :] - w[:-1, :, :])**2)\n",
        "        loss += ARR * reg_loss\n",
        "    loss.backward()\n",
        "    total_loss += loss.item() * num_graphs(data)\n",
        "    optimizer.step()\n",
        "  return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_loss(model, loader, device, regression=False, show_progress= False):\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "  if show_progress:\n",
        "    print('Testing begins ...')\n",
        "    pbar = tqdm(loader)\n",
        "  else:\n",
        "    pbar = loader\n",
        "  for data in pbar:\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "      out = model(data)\n",
        "    if regression:\n",
        "      loss += F.mse_loss(out, data.y.view(-1), reduction='sum').item()\n",
        "    else:\n",
        "      loss += F.nll_loss(out, data.y.view(-1), reduction='sum').item()\n",
        "    torch.cuda.empty_cache()\n",
        "  return loss / len(loader.dataset)\n",
        "\n",
        "def eval_rmse(model, loader, device, show_progress = False):\n",
        "  mse_loss = eval_loss(model, loader, device, True, show_progress)\n",
        "  rmse = math.sqrt(mse_loss)\n",
        "  return rmse\n",
        "\n",
        "def eval_loss_ensemble(model, checkpoints, loader, device, regression = False, show_progress = False):\n",
        "  loss = 0\n",
        "  Outs = []\n",
        "  ys = []\n",
        "  for i, checkpoint in enumerate(checkpoints):\n",
        "    if show_progress:\n",
        "      print('Testing begins...')\n",
        "      pbar = tqdm(loader)\n",
        "    else:\n",
        "      pbar = loader\n",
        "    model.load_state_dict(torch.load(checkpoint))\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    if i == 0:\n",
        "      ys = []\n",
        "    for data in pbar:\n",
        "      data = data.to(device)\n",
        "      if i == 0:\n",
        "        ys.append(data.y.view(-1))\n",
        "      with torch.no_grad():\n",
        "        out = model(data)\n",
        "        outs.append(out)\n",
        "    if i == 0:\n",
        "      ys = torch.cat(ys, 0)\n",
        "    outs = torch.cat(outs, 0).view(-1 , 1)\n",
        "    Outs.append(outs)\n",
        "  Outs = torch.cat(Outs, 1).mean(1)\n",
        "  if regression:\n",
        "    loss += F.mse_loss(Outs, ys, reduction='sum').item()\n",
        "  else:\n",
        "    loss += F.nll_loss(Outs, ys, reduction='sum').item()\n",
        "\n",
        "  return loss / len(loader.dataset)\n",
        "\n",
        "def eval_rmse_ensemble(model, checkpoints, loader, device, show_progress = False):\n",
        "  mse_loss = eval_loss_ensemble(model ,checkpoints, loader, device, True, show_progress = False)\n",
        "  rmse = math.sqrt(mse_loss)\n",
        "  return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "ETDAJ25Twa5m"
      },
      "outputs": [],
      "source": [
        "def train_multiple_epochs(train_dataset, test_dataset, model,\n",
        "                          epochs, batch_size, lr, lr_decay_factor,\n",
        "                          lr_decay_step_size, weight_decay, ARR = 0,\n",
        "                          test_freq = 1, logger = None, continue_from = None,\n",
        "                          res_dir = None, cpu_only = False):\n",
        "  rmses = []\n",
        "\n",
        "  if train_dataset.__class__.__name__ == 'MyDynamicDataset':\n",
        "    num_workers = mp.cpu_count()\n",
        "  else:\n",
        "    num_workers = 2\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size, shuffle = True, num_workers = num_workers)\n",
        "\n",
        "  if test_dataset.__class__.__name__ == 'MyDynamicDataset':\n",
        "    num_workers = mp.cpu_count()\n",
        "  else:\n",
        "    num_workers = 2\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size, shuffle = False, num_workers = num_workers)\n",
        "\n",
        "  model.to(device).reset_parameters()\n",
        "  optimizer = Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
        "  start_epoch = 1\n",
        "  if continue_from is not None:\n",
        "    if(cpu_only):\n",
        "      model.load_state_dict(\n",
        "        torch.load(\n",
        "            os.path.join(res_dir, 'model_checkpoint{}.pth'.format(continue_from)),\n",
        "            map_location=torch.device('cpu')\n",
        "            )\n",
        "      )\n",
        "      optimizer.load_state_dict(\n",
        "          torch.load(\n",
        "              os.path.join(res_dir, 'optimizer_checkpoint{}.pth'.format(continue_from)),\n",
        "              map_location=torch.device('cpu')\n",
        "              )\n",
        "      )\n",
        "    else:\n",
        "      model.load_state_dict(\n",
        "        torch.load(os.path.join(res_dir, 'model_checkpoint{}.pth'.format(continue_from)))\n",
        "      )\n",
        "      optimizer.load_state_dict(\n",
        "          torch.load(os.path.join(res_dir, 'optimizer_checkpoint{}.pth'.format(continue_from)))\n",
        "      )\n",
        "\n",
        "    start_epoch = continue_from + 1\n",
        "    epochs -= continue_from\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "  # batch_pbar = len(train_dataset) >= 100000\n",
        "  batch_pbar = True\n",
        "  t_start = time.perf_counter()\n",
        "  if not batch_pbar:\n",
        "    pbar = tqdm(range(start_epoch, epochs + start_epoch))\n",
        "  else:\n",
        "    pbar = range(start_epoch, epochs + start_epoch)\n",
        "  for epoch in pbar:\n",
        "    train_loss = train(model, optimizer, train_loader, device, regression = True,\n",
        "                       ARR = ARR, show_progress = batch_pbar, epoch=epoch)\n",
        "    if epoch % test_freq == 0:\n",
        "      rmses.append(eval_rmse(model, test_loader, device, show_progress = batch_pbar))\n",
        "    else:\n",
        "      rmses.append(np.nan)\n",
        "    eval_info = {\n",
        "      'epoch': epoch,\n",
        "      'train_loss': train_loss,\n",
        "      'test_rmse': rmses[-1],\n",
        "    }\n",
        "\n",
        "    if not batch_pbar:\n",
        "      pbar.set_description(\n",
        "          'Epoch {}, train loss {:.6f}, test rmse {:.6f}'.format(*eval_info.values())\n",
        "      )\n",
        "    else:\n",
        "      print('Epoch {}, train loss {:.6f}, test rmse {:.6f}'.format(*eval_info.values()))\n",
        "\n",
        "    if epoch % lr_decay_step_size == 0:\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr_decay_factor * param_group['lr']\n",
        "\n",
        "    if logger is not None:\n",
        "      logger(eval_info, model, optimizer)\n",
        "\n",
        "  t_end = time.perf_counter()\n",
        "  duration = t_end - t_start\n",
        "\n",
        "  print('Final Test RMSE: {:.6f}, Duration: {:.6f}'.format(rmses[-1], duration))\n",
        "\n",
        "  return rmses[-1]\n",
        "\n",
        "def test_once(test_dataset, model, batch_size, logger = None, ensemble = False, checkpoints = None):\n",
        "  test_loader = DataLoader(test_dataset, batch_size, shuffle = False)\n",
        "  model.to(device)\n",
        "  t_start = time.perf_counter()\n",
        "  if ensemble and checkpoints:\n",
        "    rmse = eval_rmse_ensemble(model, checkpoints, test_loader, device, show_progress = True)\n",
        "  else:\n",
        "    rmse = eval_rmse(model, test_loader, device, show_progress = True)\n",
        "\n",
        "  t_end = time.perf_counter()\n",
        "  duration = t_end - t_start\n",
        "  print('Test Once RMSE: {:.6f}, Duration: {:.6f}'.format(rmse, duration))\n",
        "  epoch_info = 'test_once' if not ensemble else 'ensemble'\n",
        "  eval_info = {\n",
        "      'epoch': epoch_info,\n",
        "      'train_loss': 0,\n",
        "      'test_rmse': rmse,\n",
        "  }\n",
        "\n",
        "  if logger is not None:\n",
        "    logger(eval_info, None, None)\n",
        "\n",
        "  return rmse\n",
        "\n",
        "def num_graphs(data):\n",
        "  if data.batch is not None:\n",
        "    return data.num_graphs\n",
        "  else:\n",
        "    return data.x.size(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzfYCAN8VBsC"
      },
      "source": [
        "### Load data and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "CO29cuGn3ADj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def map_data(data):\n",
        "  \"\"\"\n",
        "  Map data to proper indices in case they are not in a continues [0,N) range\n",
        "  \"\"\"\n",
        "  uniq = list(set(data))\n",
        "  id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
        "  data = np.array([id_dict[x] for x in data])\n",
        "  n = len(uniq)\n",
        "\n",
        "  return data, id_dict, n\n",
        "\n",
        "def process_data(dataset, seed = 1234, verbose = True):\n",
        "  num_users, num_items, u_nodes_ratings, v_nodes_ratings, ratings, u_features, v_features = None, None, None, None, None, None, None\n",
        "\n",
        "  # shuffle here like cf-nade paper with python's own random class\n",
        "  # make sure to convert to list, otherwise random.shuffle acts weird on it without a warning\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  random.seed(seed)\n",
        "  random.shuffle(data_array)\n",
        "  data_array = np.array(data_array)\n",
        "\n",
        "  u_nodes_ratings = data_array[:, 0].astype(np.int32)\n",
        "  v_nodes_ratings = data_array[:, 1].astype(np.int32)\n",
        "  ratings = data_array[:, 2].astype(np.float32)\n",
        "\n",
        "  u_nodes_ratings, u_dict, num_users = map_data(u_nodes_ratings)\n",
        "  v_nodes_ratings, v_dict, num_items = map_data(v_nodes_ratings)\n",
        "\n",
        "  u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int32)\n",
        "  ratings = ratings.astype(np.float64)\n",
        "\n",
        "  # Movie features (genres)\n",
        "  genre_headers = dataset.movies_df.columns.values[6:]\n",
        "  num_genres = genre_headers.shape[0]\n",
        "\n",
        "  v_features = np.zeros((num_items, num_genres), dtype=np.float32)\n",
        "  for movie_id, g_vec in zip(dataset.movies_df['movie id'].values.tolist(), dataset.movies_df[genre_headers].values.tolist()):\n",
        "    # Check if movie_id was listed in ratings file and therefore in mapping dictionary\n",
        "    if movie_id in v_dict.keys():\n",
        "      v_features[v_dict[movie_id], :] = g_vec\n",
        "\n",
        "  # User features\n",
        "  sep = r'|'\n",
        "  occupation = set(dataset.users_df['occupation'].values.tolist())\n",
        "\n",
        "  gender_dict = {'M': 0., 'F': 1.}\n",
        "  occupation_dict = {f: i for i, f in enumerate(occupation, start=2)}\n",
        "\n",
        "  num_feats = 2 + len(occupation_dict)\n",
        "\n",
        "  u_features = np.zeros((num_users, num_feats), dtype=np.float32)\n",
        "  for _, row in dataset.users_df.iterrows():\n",
        "    u_id = row['user id']\n",
        "    if u_id in u_dict.keys():\n",
        "      # age\n",
        "      u_features[u_dict[u_id], 0] = row['age']\n",
        "      # gender\n",
        "      u_features[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
        "      # occupation\n",
        "      u_features[u_dict[u_id], occupation_dict[row['occupation']]] = 1.\n",
        "\n",
        "  u_features = sp.csr_matrix(u_features)\n",
        "  v_features = sp.csr_matrix(v_features)\n",
        "\n",
        "  return num_users, num_items, u_nodes_ratings, v_nodes_ratings, ratings, u_features, v_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "xIg2ecUs0qBJ"
      },
      "outputs": [],
      "source": [
        "def create_trainvaltest_split(dataset, seed=1212, testing=False,\n",
        "               verbose=True, rating_map=None,\n",
        "               post_rating_map=None, ratio=1.0):\n",
        "  num_users, num_items, u_nodes, v_nodes, ratings, u_features, v_features = process_data(dataset, seed=seed, verbose=verbose)\n",
        "\n",
        "  if rating_map is not None:\n",
        "    for i, x in enumerate(ratings):\n",
        "      ratings[i] = rating_map[x]\n",
        "\n",
        "  rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
        "\n",
        "  # number of test and validation edges\n",
        "\n",
        "  print(\"Spliting the dataset ...\")\n",
        "  num_test = int(np.ceil(ratings.shape[0] * 0.1))\n",
        "  num_val = int(np.ceil(ratings.shape[0] * 0.9 * 0.05))\n",
        "  num_train = ratings.shape[0] - num_val - num_test\n",
        "\n",
        "  pairs_nonzero = np.vstack([u_nodes, v_nodes]).transpose()\n",
        "\n",
        "  train_pairs_idx = pairs_nonzero[0:int(num_train*ratio)]\n",
        "  val_pairs_idx = pairs_nonzero[num_train:num_train + num_val]\n",
        "  test_pairs_idx = pairs_nonzero[num_train + num_val:]\n",
        "\n",
        "  u_test_idx, v_test_idx = test_pairs_idx.transpose()\n",
        "  u_val_idx, v_val_idx = val_pairs_idx.transpose()\n",
        "  u_train_idx, v_train_idx = train_pairs_idx.transpose()\n",
        "\n",
        "  # create labels\n",
        "  all_labels = np.array([rating_dict[r] for r in ratings], dtype=np.int32)\n",
        "  train_labels = all_labels[0:int(num_train*ratio)]\n",
        "  val_labels = all_labels[num_train:num_train + num_val]\n",
        "  test_labels = all_labels[num_train + num_val:]\n",
        "\n",
        "  if testing:\n",
        "    u_train_idx = np.hstack([u_train_idx, u_val_idx])\n",
        "    v_train_idx = np.hstack([v_train_idx, v_val_idx])\n",
        "    train_labels = np.hstack([train_labels, val_labels])\n",
        "\n",
        "  class_values = np.sort(np.unique(ratings))\n",
        "\n",
        "  # make training adjacency matrix\n",
        "  if post_rating_map is None:\n",
        "    data = train_labels + 1.\n",
        "  else:\n",
        "    data = np.array([post_rating_map[r] for r in class_values[train_labels]]) + 1.\n",
        "  data = data.astype(np.float32)\n",
        "\n",
        "  rating_mx_train = sp.csr_matrix((data, [u_train_idx, v_train_idx]),\n",
        "                                  shape=[num_users, num_items], dtype=np.float32)\n",
        "\n",
        "  return u_features, v_features, rating_mx_train, train_labels, u_train_idx, v_train_idx, val_labels, u_val_idx, v_val_idx, test_labels, u_test_idx, v_test_idx, class_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z23qqQ9n0gE9",
        "outputId": "ae1a091b-e1e9-434b-8d61-d7e177667f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spliting the dataset ...\n"
          ]
        }
      ],
      "source": [
        "u_features, v_features, adj_train, train_labels, train_u_indices, train_v_indices, val_labels, val_u_indices, val_v_indices, test_labels, test_u_indices, test_v_indices, class_values = create_trainvaltest_split(dataset, 1212, False, True, None, None, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "15vzGFIaRE-W"
      },
      "outputs": [],
      "source": [
        "!mkdir ml-1m ml-1m/train ml-1m/test ml-1m/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "k2CE0S5D0Ovh"
      },
      "outputs": [],
      "source": [
        "dataset_class = 'MyDynamicDataset'\n",
        "train_indices = (train_u_indices, train_v_indices)\n",
        "val_indices = (val_u_indices, val_v_indices)\n",
        "test_indices = (test_u_indices, test_v_indices)\n",
        "train_graphs = eval(dataset_class)(\n",
        "    'ml-1m/train',\n",
        "    adj_train,\n",
        "    train_indices,\n",
        "    train_labels,\n",
        "    1,\n",
        "    1.0,\n",
        "    100,\n",
        "    u_features,\n",
        "    v_features,\n",
        "    class_values,\n",
        "    max_num=None\n",
        ")\n",
        "\n",
        "test_graphs = eval(dataset_class)(\n",
        "    'ml-1m/test',\n",
        "    adj_train,\n",
        "    test_indices,\n",
        "    test_labels,\n",
        "    1,\n",
        "    1.0,\n",
        "    100,\n",
        "    u_features,\n",
        "    v_features,\n",
        "    class_values,\n",
        "    max_num= None\n",
        ")\n",
        "\n",
        "val_graphs = eval(dataset_class)(\n",
        "    'ml-1m/val',\n",
        "    adj_train,\n",
        "    val_indices,\n",
        "    val_labels,\n",
        "    1,\n",
        "    1.0,\n",
        "    100,\n",
        "    u_features,\n",
        "    v_features,\n",
        "    class_values,\n",
        "    max_num= None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = eval('MyDynamicDataset')(root='ml-1m/train', A=adj_train,\n",
        "    links=(train_u_indices, train_v_indices), labels=train_labels, h=1, sample_ratio=1.0,\n",
        "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
        "val_dataset = eval('MyDynamicDataset')(root='ml-1m/val', A=adj_train,\n",
        "    links=(val_u_indices, val_v_indices), labels=val_labels, h=1, sample_ratio=1.0,\n",
        "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
        "test_dataset = eval('MyDynamicDataset')(root='ml-1m/test', A=adj_train,\n",
        "    links=(test_u_indices, test_v_indices), labels=test_labels, h=1, sample_ratio=1.0,\n",
        "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
        "\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eOLsZFACvjd",
        "outputId": "14c804ee-5ea2-4136-b660-d9d47288affd"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85500, 4500, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_relations = len(class_values)\n",
        "multiply_by = 1\n",
        "\n",
        "model = IGMC(train_graphs, latent_dim = [32, 32, 32, 32],\n",
        "             num_relations = num_relations, num_bases = 4,\n",
        "             regression = True, adj_dropout = 0.2, force_undirected = False,\n",
        "             side_features = False, n_side_features = 0, multiply_by = 1\n",
        ")"
      ],
      "metadata": {
        "id": "_pFRqjzy67VP"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "eOU_I_cs7Up_"
      },
      "outputs": [],
      "source": [
        "def logger(info, model, optimizer):\n",
        "  epoch, train_loss, test_rmse = info['epoch'], info['train_loss'], info['test_rmse']\n",
        "  with open(os.path.join('ml-1m/train/', 'log.txt'), 'a') as f:\n",
        "    f.write('Epoch {}, train loss {:.4f}, test rmse {:.6f}\\n'.format(epoch, train_loss, test_rmse))\n",
        "  if type(epoch) == int and epoch % args['save_interval'] == 0:\n",
        "    print('Saving model states...')\n",
        "    model_name = os.path.join('ml-1m/train/', 'model_checkpoint{}.pth'.format(epoch))\n",
        "    optimizer_name = os.path.join(\n",
        "        'ml-1m/train/', 'optimizer_checkpoint{}.pth'.format(epoch)\n",
        "    )\n",
        "    if model is not None:\n",
        "      torch.save(model.state_dict(), model_name)\n",
        "    if optimizer is not None:\n",
        "      torch.save(optimizer.state_dict(), optimizer_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j_dk_SWxJqB",
        "outputId": "ac933aed-a1b8-4008-c187-45b752eb6f92",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1, batch loss: 1.214111566543579: 100%|██████████| 1710/1710 [10:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing begins ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|██████████| 90/90 [00:25<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, train loss 1.455307, test rmse 0.963161\n",
            "Saving model states...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2, batch loss: 0.6509255170822144: 100%|██████████| 1710/1710 [10:17<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing begins ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|██████████| 90/90 [00:25<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, train loss 1.155056, test rmse 1.001294\n",
            "Saving model states...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3, batch loss: 1.1597026586532593: 100%|██████████| 1710/1710 [10:03<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing begins ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|██████████| 90/90 [00:26<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, train loss 1.069708, test rmse 0.982991\n",
            "Saving model states...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4, batch loss: 1.1350752115249634: 100%|██████████| 1710/1710 [10:04<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing begins ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|██████████| 90/90 [00:25<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, train loss 1.015289, test rmse 0.946835\n",
            "Saving model states...\n",
            "Final Test RMSE: 0.946835, Duration: 2540.536522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9468349097745234"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "args = {\n",
        "    'save_interval': 1\n",
        "}\n",
        "train_multiple_epochs(\n",
        "        train_dataset,\n",
        "        val_dataset,\n",
        "        model,\n",
        "        4,\n",
        "        50,\n",
        "        1e-3,\n",
        "        lr_decay_factor = 0.1 ,\n",
        "        lr_decay_step_size = 20,\n",
        "        weight_decay = 0,\n",
        "        ARR = 0.001,\n",
        "        test_freq = 1,\n",
        "        logger = logger,\n",
        "        continue_from = None,\n",
        "        res_dir= 'ml-1m/train',\n",
        "        cpu_only = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZz1ZQfzZ-wH"
      },
      "source": [
        " # Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(dataset, seed = 1234, verbose = True):\n",
        "  num_users, num_items, u_nodes_ratings, v_nodes_ratings, ratings, u_features, v_features = None, None, None, None, None, None, None\n",
        "\n",
        "  # shuffle here like cf-nade paper with python's own random class\n",
        "  # make sure to convert to list, otherwise random.shuffle acts weird on it without a warning\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  random.seed(seed)\n",
        "  random.shuffle(data_array)\n",
        "  data_array = np.array(data_array)\n",
        "\n",
        "  u_nodes_ratings = data_array[:, 0].astype(np.int32)\n",
        "  v_nodes_ratings = data_array[:, 1].astype(np.int32)\n",
        "  ratings = data_array[:, 2].astype(np.float32)\n",
        "\n",
        "  u_nodes_ratings, u_dict, num_users = map_data(u_nodes_ratings)\n",
        "  v_nodes_ratings, v_dict, num_items = map_data(v_nodes_ratings)\n",
        "\n",
        "  u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int32)\n",
        "  ratings = ratings.astype(np.float64)\n",
        "\n",
        "  # Movie features (genres)\n",
        "  genre_headers = dataset.movies_df.columns.values[6:]\n",
        "  num_genres = genre_headers.shape[0]\n",
        "\n",
        "  v_features = np.zeros((num_items, num_genres), dtype=np.float32)\n",
        "  for movie_id, g_vec in zip(dataset.movies_df['movie id'].values.tolist(), dataset.movies_df[genre_headers].values.tolist()):\n",
        "    # Check if movie_id was listed in ratings file and therefore in mapping dictionary\n",
        "    if movie_id in v_dict.keys():\n",
        "      v_features[v_dict[movie_id], :] = g_vec\n",
        "\n",
        "  # User features\n",
        "  sep = r'|'\n",
        "  occupation = set(dataset.users_df['occupation'].values.tolist())\n",
        "\n",
        "  gender_dict = {'M': 0., 'F': 1.}\n",
        "  occupation_dict = {f: i for i, f in enumerate(occupation, start=2)}\n",
        "\n",
        "  num_feats = 2 + len(occupation_dict)\n",
        "\n",
        "  u_features = np.zeros((num_users, num_feats), dtype=np.float32)\n",
        "  for _, row in dataset.users_df.iterrows():\n",
        "    u_id = row['user id']\n",
        "    if u_id in u_dict.keys():\n",
        "      # age\n",
        "      u_features[u_dict[u_id], 0] = row['age']\n",
        "      # gender\n",
        "      u_features[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
        "      # occupation\n",
        "      u_features[u_dict[u_id], occupation_dict[row['occupation']]] = 1.\n",
        "\n",
        "  u_features = sp.csr_matrix(u_features)\n",
        "  v_features = sp.csr_matrix(v_features)\n",
        "\n",
        "  return num_users, num_items, u_nodes_ratings, v_nodes_ratings, ratings, u_features, v_features"
      ],
      "metadata": {
        "id": "HZCNIPL5RkFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LCW_nm0aX6z",
        "outputId": "2b31c29c-3a0a-4935-b4e6-166596781840",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing begins ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10003 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  0%|          | 23/10003 [00:00<06:14, 26.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 58/10003 [00:03<15:40, 10.57it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 69/10003 [00:04<28:36,  5.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 76/10003 [00:05<21:58,  7.53it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 87/10003 [00:06<13:00, 12.71it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 91/10003 [00:07<12:26, 13.28it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 101/10003 [00:08<18:53,  8.74it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|          | 107/10003 [00:09<31:01,  5.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|▏         | 134/10003 [00:10<06:29, 25.31it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  1%|▏         | 143/10003 [00:11<06:28, 25.41it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  2%|▏         | 169/10003 [00:12<05:57, 27.52it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  2%|▏         | 219/10003 [00:13<05:51, 27.84it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  2%|▏         | 228/10003 [00:14<06:02, 26.95it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  3%|▎         | 254/10003 [00:15<05:50, 27.83it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  3%|▎         | 294/10003 [00:16<08:25, 19.23it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  3%|▎         | 313/10003 [00:17<08:33, 18.86it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  3%|▎         | 321/10003 [00:18<08:41, 18.55it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  3%|▎         | 340/10003 [00:19<07:53, 20.42it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  4%|▎         | 357/10003 [00:20<08:49, 18.22it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  4%|▍         | 377/10003 [00:21<06:27, 24.84it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  4%|▍         | 425/10003 [00:22<05:53, 27.07it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  4%|▍         | 437/10003 [00:23<06:05, 26.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  5%|▍         | 461/10003 [00:24<05:49, 27.33it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  5%|▍         | 485/10003 [00:24<05:45, 27.52it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  5%|▌         | 531/10003 [00:26<06:16, 25.17it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  5%|▌         | 540/10003 [00:27<05:57, 26.47it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  6%|▌         | 567/10003 [00:28<05:45, 27.31it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  6%|▌         | 614/10003 [00:29<05:46, 27.09it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  6%|▋         | 638/10003 [00:30<06:00, 25.96it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  6%|▋         | 647/10003 [00:31<07:34, 20.58it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  7%|▋         | 665/10003 [00:32<07:51, 19.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  7%|▋         | 685/10003 [00:33<07:53, 19.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  7%|▋         | 705/10003 [00:34<08:42, 17.78it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  7%|▋         | 744/10003 [00:35<05:43, 26.94it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  8%|▊         | 753/10003 [00:36<05:39, 27.21it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  8%|▊         | 778/10003 [00:37<05:34, 27.56it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  8%|▊         | 824/10003 [00:38<05:38, 27.08it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  8%|▊         | 833/10003 [00:39<06:01, 25.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  9%|▊         | 859/10003 [00:40<05:24, 28.16it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  9%|▉         | 906/10003 [00:41<05:44, 26.43it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  9%|▉         | 918/10003 [00:42<05:40, 26.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "  9%|▉         | 942/10003 [00:43<05:28, 27.57it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 10%|▉         | 990/10003 [00:44<05:27, 27.53it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 10%|█         | 1008/10003 [00:45<07:06, 21.11it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 10%|█         | 1017/10003 [00:46<07:44, 19.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 10%|█         | 1034/10003 [00:47<07:42, 19.39it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 11%|█         | 1053/10003 [00:48<07:53, 18.88it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 11%|█         | 1069/10003 [00:49<08:35, 17.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 11%|█         | 1117/10003 [00:50<05:23, 27.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 11%|█▏        | 1141/10003 [00:51<05:22, 27.49it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 12%|█▏        | 1153/10003 [00:52<05:40, 25.98it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 12%|█▏        | 1177/10003 [00:53<05:31, 26.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 12%|█▏        | 1223/10003 [00:54<05:15, 27.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 12%|█▏        | 1229/10003 [00:54<05:19, 27.47it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 13%|█▎        | 1258/10003 [00:55<05:00, 29.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 13%|█▎        | 1306/10003 [00:57<05:53, 24.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 13%|█▎        | 1315/10003 [00:58<05:27, 26.54it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 13%|█▎        | 1342/10003 [00:59<05:10, 27.86it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 14%|█▎        | 1375/10003 [01:00<07:33, 19.01it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 14%|█▍        | 1383/10003 [01:01<07:28, 19.22it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 14%|█▍        | 1402/10003 [01:02<06:53, 20.80it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 14%|█▍        | 1435/10003 [01:03<06:10, 23.14it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 14%|█▍        | 1444/10003 [01:04<05:27, 26.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 15%|█▍        | 1473/10003 [01:05<05:08, 27.69it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 15%|█▌        | 1520/10003 [01:06<05:03, 27.94it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 15%|█▌        | 1532/10003 [01:07<05:17, 26.69it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 16%|█▌        | 1556/10003 [01:08<05:08, 27.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 16%|█▌        | 1602/10003 [01:09<04:58, 28.17it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 16%|█▌        | 1614/10003 [01:10<05:09, 27.09it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 16%|█▋        | 1638/10003 [01:11<05:10, 26.92it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 17%|█▋        | 1689/10003 [01:12<04:49, 28.68it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 17%|█▋        | 1713/10003 [01:13<06:07, 22.54it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 17%|█▋        | 1719/10003 [01:14<06:38, 20.77it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 17%|█▋        | 1737/10003 [01:14<06:40, 20.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 18%|█▊        | 1772/10003 [01:16<06:22, 21.50it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 18%|█▊        | 1781/10003 [01:17<06:59, 19.61it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 18%|█▊        | 1823/10003 [01:18<05:04, 26.88it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 18%|█▊        | 1847/10003 [01:19<05:20, 25.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 19%|█▊        | 1859/10003 [01:20<05:07, 26.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 19%|█▉        | 1880/10003 [01:20<04:55, 27.49it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 19%|█▉        | 1932/10003 [01:22<04:56, 27.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 19%|█▉        | 1941/10003 [01:23<04:51, 27.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 20%|█▉        | 1965/10003 [01:24<05:01, 26.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 20%|██        | 2013/10003 [01:25<04:37, 28.80it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 20%|██        | 2025/10003 [01:26<04:45, 27.99it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 20%|██        | 2049/10003 [01:27<04:50, 27.38it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 21%|██        | 2088/10003 [01:28<06:25, 20.52it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 21%|██        | 2094/10003 [01:29<06:53, 19.14it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 21%|██        | 2111/10003 [01:29<06:27, 20.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 21%|██▏       | 2144/10003 [01:31<07:26, 17.61it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 22%|██▏       | 2170/10003 [01:32<04:37, 28.18it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 22%|██▏       | 2182/10003 [01:33<04:47, 27.22it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 22%|██▏       | 2203/10003 [01:33<04:56, 26.34it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 23%|██▎       | 2251/10003 [01:35<04:49, 26.77it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 23%|██▎       | 2278/10003 [01:36<04:34, 28.14it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 23%|██▎       | 2288/10003 [01:37<04:33, 28.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 23%|██▎       | 2335/10003 [01:38<04:32, 28.15it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 23%|██▎       | 2348/10003 [01:39<04:30, 28.26it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 24%|██▎       | 2370/10003 [01:39<04:31, 28.11it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 24%|██▍       | 2420/10003 [01:41<04:38, 27.23it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 24%|██▍       | 2441/10003 [01:42<06:16, 20.09it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 24%|██▍       | 2447/10003 [01:43<06:20, 19.88it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 25%|██▍       | 2465/10003 [01:44<06:09, 20.41it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 25%|██▍       | 2489/10003 [01:45<06:03, 20.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 25%|██▌       | 2507/10003 [01:46<06:17, 19.84it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 26%|██▌       | 2553/10003 [01:47<04:30, 27.57it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 26%|██▌       | 2565/10003 [01:48<04:42, 26.37it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 26%|██▌       | 2589/10003 [01:49<04:28, 27.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 26%|██▋       | 2637/10003 [01:50<04:31, 27.18it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 26%|██▋       | 2646/10003 [01:51<04:29, 27.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 27%|██▋       | 2673/10003 [01:52<04:17, 28.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 27%|██▋       | 2720/10003 [01:53<04:22, 27.71it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 27%|██▋       | 2729/10003 [01:54<04:25, 27.42it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 28%|██▊       | 2754/10003 [01:55<04:18, 27.99it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 28%|██▊       | 2797/10003 [01:56<05:29, 21.85it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 28%|██▊       | 2818/10003 [01:57<06:17, 19.01it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 28%|██▊       | 2824/10003 [01:58<06:35, 18.16it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 28%|██▊       | 2844/10003 [01:59<05:51, 20.37it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 29%|██▊       | 2861/10003 [02:00<06:35, 18.07it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 29%|██▉       | 2890/10003 [02:01<04:23, 26.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 29%|██▉       | 2939/10003 [02:02<04:26, 26.54it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 30%|██▉       | 2963/10003 [02:03<04:08, 28.30it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 30%|██▉       | 2975/10003 [02:04<04:19, 27.07it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 30%|██▉       | 2999/10003 [02:05<04:33, 25.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 30%|███       | 3044/10003 [02:06<04:10, 27.83it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 31%|███       | 3054/10003 [02:07<04:19, 26.75it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 31%|███       | 3082/10003 [02:08<04:05, 28.21it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 31%|███       | 3117/10003 [02:09<06:07, 18.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 31%|███▏      | 3134/10003 [02:10<07:17, 15.69it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 31%|███▏      | 3140/10003 [02:11<07:28, 15.31it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3154/10003 [02:12<07:37, 14.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3168/10003 [02:13<07:57, 14.31it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3198/10003 [02:14<06:03, 18.74it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3214/10003 [02:15<06:22, 17.75it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3222/10003 [02:16<05:14, 21.59it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 32%|███▏      | 3246/10003 [02:17<04:18, 26.09it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 33%|███▎      | 3294/10003 [02:18<04:06, 27.22it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 33%|███▎      | 3303/10003 [02:19<04:21, 25.62it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 33%|███▎      | 3327/10003 [02:20<04:22, 25.40it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 34%|███▍      | 3377/10003 [02:21<04:02, 27.38it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 34%|███▍      | 3386/10003 [02:22<04:09, 26.57it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 34%|███▍      | 3413/10003 [02:23<04:09, 26.42it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 34%|███▍      | 3437/10003 [02:24<03:57, 27.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 35%|███▍      | 3484/10003 [02:25<03:57, 27.50it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 35%|███▍      | 3490/10003 [02:26<04:46, 22.70it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 35%|███▌      | 3525/10003 [02:27<05:37, 19.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 35%|███▌      | 3544/10003 [02:28<05:31, 19.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 36%|███▌      | 3561/10003 [02:29<06:11, 17.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 36%|███▌      | 3567/10003 [02:30<06:17, 17.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 36%|███▌      | 3591/10003 [02:31<04:01, 26.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 36%|███▌      | 3618/10003 [02:32<04:02, 26.29it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 36%|███▋      | 3645/10003 [02:33<03:53, 27.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 37%|███▋      | 3690/10003 [02:34<04:04, 25.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 37%|███▋      | 3702/10003 [02:35<04:01, 26.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 37%|███▋      | 3726/10003 [02:36<03:55, 26.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 38%|███▊      | 3772/10003 [02:37<03:42, 28.00it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 38%|███▊      | 3799/10003 [02:38<03:48, 27.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 38%|███▊      | 3808/10003 [02:39<03:54, 26.42it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 38%|███▊      | 3832/10003 [02:40<04:04, 25.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 39%|███▊      | 3865/10003 [02:41<04:48, 21.27it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 39%|███▊      | 3873/10003 [02:42<05:14, 19.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 39%|███▉      | 3892/10003 [02:42<04:42, 21.61it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 39%|███▉      | 3927/10003 [02:44<04:23, 23.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 39%|███▉      | 3936/10003 [02:45<03:56, 25.70it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 40%|███▉      | 3963/10003 [02:46<03:39, 27.55it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 40%|████      | 4010/10003 [02:47<03:37, 27.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 40%|████      | 4022/10003 [02:48<03:52, 25.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 40%|████      | 4046/10003 [02:49<03:45, 26.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 41%|████      | 4091/10003 [02:50<03:41, 26.68it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 41%|████      | 4100/10003 [02:51<03:48, 25.83it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 41%|████▏     | 4129/10003 [02:52<03:29, 27.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 42%|████▏     | 4153/10003 [02:53<03:32, 27.47it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 42%|████▏     | 4180/10003 [02:54<03:31, 27.49it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 42%|████▏     | 4204/10003 [02:55<04:40, 20.65it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 42%|████▏     | 4236/10003 [02:56<04:52, 19.70it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 42%|████▏     | 4244/10003 [02:57<05:12, 18.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 43%|████▎     | 4262/10003 [02:58<05:47, 16.53it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 43%|████▎     | 4282/10003 [02:59<03:57, 24.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 43%|████▎     | 4310/10003 [03:00<03:30, 27.02it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 43%|████▎     | 4334/10003 [03:01<03:37, 26.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 44%|████▍     | 4382/10003 [03:02<03:20, 28.03it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 44%|████▍     | 4406/10003 [03:03<03:24, 27.40it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 44%|████▍     | 4418/10003 [03:04<03:31, 26.38it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 44%|████▍     | 4442/10003 [03:05<03:36, 25.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 45%|████▍     | 4488/10003 [03:06<03:28, 26.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 45%|████▌     | 4512/10003 [03:07<03:26, 26.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 45%|████▌     | 4524/10003 [03:08<03:22, 27.03it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 45%|████▌     | 4545/10003 [03:09<04:10, 21.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 46%|████▌     | 4566/10003 [03:10<04:18, 21.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 46%|████▌     | 4584/10003 [03:10<04:29, 20.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 46%|████▌     | 4619/10003 [03:12<05:09, 17.39it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 46%|████▋     | 4642/10003 [03:13<03:28, 25.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 47%|████▋     | 4654/10003 [03:14<03:23, 26.34it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 47%|████▋     | 4678/10003 [03:15<03:17, 26.95it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 47%|████▋     | 4705/10003 [03:16<03:23, 26.01it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 47%|████▋     | 4729/10003 [03:16<03:13, 27.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 48%|████▊     | 4778/10003 [03:18<03:16, 26.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 48%|████▊     | 4802/10003 [03:19<03:07, 27.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 48%|████▊     | 4811/10003 [03:20<03:36, 23.95it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 48%|████▊     | 4835/10003 [03:20<03:12, 26.86it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 49%|████▉     | 4880/10003 [03:22<03:18, 25.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 49%|████▉     | 4889/10003 [03:23<03:26, 24.80it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 49%|████▉     | 4922/10003 [03:24<04:16, 19.78it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 49%|████▉     | 4931/10003 [03:25<04:22, 19.29it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 49%|████▉     | 4949/10003 [03:26<04:03, 20.74it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 50%|████▉     | 4966/10003 [03:27<04:50, 17.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 50%|████▉     | 4995/10003 [03:28<03:01, 27.56it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 50%|█████     | 5019/10003 [03:29<03:03, 27.16it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 50%|█████     | 5043/10003 [03:29<03:03, 27.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 51%|█████     | 5093/10003 [03:31<03:05, 26.49it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 51%|█████     | 5117/10003 [03:32<02:55, 27.87it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 51%|█████▏    | 5129/10003 [03:33<02:56, 27.59it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 52%|█████▏    | 5171/10003 [03:34<02:55, 27.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 52%|█████▏    | 5180/10003 [03:35<03:03, 26.33it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 52%|█████▏    | 5229/10003 [03:36<03:00, 26.39it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 52%|█████▏    | 5247/10003 [03:37<03:54, 20.26it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 53%|█████▎    | 5266/10003 [03:38<03:55, 20.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 53%|█████▎    | 5287/10003 [03:39<04:03, 19.34it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 53%|█████▎    | 5293/10003 [03:40<04:18, 18.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 53%|█████▎    | 5308/10003 [03:40<04:16, 18.33it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 53%|█████▎    | 5331/10003 [03:42<03:00, 25.81it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 54%|█████▍    | 5377/10003 [03:43<03:00, 25.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 54%|█████▍    | 5386/10003 [03:44<02:50, 27.07it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 54%|█████▍    | 5415/10003 [03:45<02:40, 28.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 54%|█████▍    | 5439/10003 [03:46<02:46, 27.47it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 55%|█████▍    | 5469/10003 [03:47<02:39, 28.36it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 55%|█████▍    | 5493/10003 [03:48<02:43, 27.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 55%|█████▌    | 5539/10003 [03:49<02:48, 26.53it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 55%|█████▌    | 5551/10003 [03:50<02:57, 25.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 56%|█████▌    | 5575/10003 [03:51<02:46, 26.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 56%|█████▌    | 5614/10003 [03:52<03:47, 19.33it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 56%|█████▋    | 5630/10003 [03:53<03:45, 19.43it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 56%|█████▋    | 5639/10003 [03:54<03:48, 19.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 57%|█████▋    | 5655/10003 [03:55<03:58, 18.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 57%|█████▋    | 5692/10003 [03:56<02:43, 26.43it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 57%|█████▋    | 5701/10003 [03:57<02:38, 27.13it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 57%|█████▋    | 5749/10003 [03:58<02:36, 27.13it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 58%|█████▊    | 5773/10003 [03:59<02:40, 26.29it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 58%|█████▊    | 5785/10003 [04:00<02:35, 27.13it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 58%|█████▊    | 5809/10003 [04:01<02:37, 26.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 59%|█████▊    | 5854/10003 [04:02<02:44, 25.20it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 59%|█████▊    | 5863/10003 [04:03<02:37, 26.30it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 59%|█████▉    | 5887/10003 [04:04<02:35, 26.53it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 59%|█████▉    | 5932/10003 [04:05<02:29, 27.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 59%|█████▉    | 5941/10003 [04:06<02:59, 22.69it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 60%|█████▉    | 5962/10003 [04:07<03:13, 20.93it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 60%|█████▉    | 5980/10003 [04:08<03:19, 20.20it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 60%|██████    | 6012/10003 [04:09<03:45, 17.71it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 60%|██████    | 6018/10003 [04:10<03:49, 17.39it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 60%|██████    | 6044/10003 [04:11<02:34, 25.58it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 61%|██████    | 6065/10003 [04:11<02:33, 25.73it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 61%|██████    | 6092/10003 [04:12<02:26, 26.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 61%|██████▏   | 6143/10003 [04:14<02:19, 27.75it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 62%|██████▏   | 6167/10003 [04:15<02:24, 26.54it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 62%|██████▏   | 6173/10003 [04:15<02:23, 26.70it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 62%|██████▏   | 6203/10003 [04:17<02:16, 27.90it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 62%|██████▏   | 6246/10003 [04:18<02:24, 26.08it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 63%|██████▎   | 6256/10003 [04:19<02:18, 27.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 63%|██████▎   | 6298/10003 [04:20<02:59, 20.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 63%|██████▎   | 6316/10003 [04:21<02:57, 20.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 63%|██████▎   | 6337/10003 [04:22<03:06, 19.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 63%|██████▎   | 6346/10003 [04:23<02:59, 20.40it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 64%|██████▎   | 6362/10003 [04:24<03:13, 18.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 64%|██████▍   | 6387/10003 [04:25<02:24, 25.11it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 64%|██████▍   | 6411/10003 [04:26<02:12, 27.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▍   | 6453/10003 [04:27<03:00, 19.71it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▍   | 6459/10003 [04:28<02:57, 20.00it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▍   | 6479/10003 [04:29<03:07, 18.83it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▍   | 6495/10003 [04:30<02:59, 19.57it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▌   | 6517/10003 [04:31<02:58, 19.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 65%|██████▌   | 6536/10003 [04:32<02:35, 22.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 66%|██████▌   | 6584/10003 [04:33<02:07, 26.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 66%|██████▌   | 6593/10003 [04:34<02:25, 23.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 66%|██████▌   | 6611/10003 [04:34<02:33, 22.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 66%|██████▋   | 6646/10003 [04:36<02:58, 18.81it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 67%|██████▋   | 6663/10003 [04:37<02:45, 20.16it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 67%|██████▋   | 6684/10003 [04:38<03:08, 17.60it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 67%|██████▋   | 6705/10003 [04:39<02:11, 25.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 67%|██████▋   | 6717/10003 [04:40<02:06, 25.99it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 67%|██████▋   | 6738/10003 [04:40<02:02, 26.65it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 68%|██████▊   | 6786/10003 [04:42<02:05, 25.59it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 68%|██████▊   | 6810/10003 [04:43<02:02, 26.16it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 68%|██████▊   | 6822/10003 [04:44<02:03, 25.85it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 68%|██████▊   | 6846/10003 [04:45<01:57, 26.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 69%|██████▉   | 6888/10003 [04:46<01:57, 26.41it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 69%|██████▉   | 6897/10003 [04:47<01:59, 25.88it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 69%|██████▉   | 6925/10003 [04:48<01:58, 26.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|██████▉   | 6964/10003 [04:49<02:25, 20.94it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|██████▉   | 6972/10003 [04:50<02:40, 18.86it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|██████▉   | 6990/10003 [04:51<02:46, 18.06it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|███████   | 7022/10003 [04:52<02:42, 18.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|███████   | 7029/10003 [04:53<02:44, 18.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 70%|███████   | 7049/10003 [04:54<01:57, 25.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 71%|███████   | 7094/10003 [04:55<01:49, 26.52it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 71%|███████   | 7103/10003 [04:56<01:50, 26.30it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 71%|███████▏  | 7130/10003 [04:57<01:48, 26.55it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 72%|███████▏  | 7173/10003 [04:58<01:51, 25.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 72%|███████▏  | 7185/10003 [04:59<01:47, 26.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 72%|███████▏  | 7209/10003 [05:00<01:48, 25.73it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7254/10003 [05:01<01:45, 26.18it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7263/10003 [05:02<01:44, 26.32it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7287/10003 [05:03<01:41, 26.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7326/10003 [05:04<02:11, 20.42it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7343/10003 [05:05<02:26, 18.13it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 73%|███████▎  | 7352/10003 [05:06<02:19, 18.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 74%|███████▎  | 7372/10003 [05:07<02:17, 19.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 74%|███████▍  | 7386/10003 [05:08<02:28, 17.59it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 74%|███████▍  | 7413/10003 [05:09<01:40, 25.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 75%|███████▍  | 7459/10003 [05:10<01:31, 27.65it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 75%|███████▍  | 7486/10003 [05:11<01:34, 26.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 75%|███████▍  | 7498/10003 [05:12<01:35, 26.37it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 75%|███████▌  | 7522/10003 [05:13<01:35, 26.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 76%|███████▌  | 7564/10003 [05:14<01:28, 27.48it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 76%|███████▌  | 7576/10003 [05:15<01:29, 27.20it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 76%|███████▌  | 7600/10003 [05:16<01:32, 26.01it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 76%|███████▋  | 7645/10003 [05:17<01:31, 25.63it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7654/10003 [05:18<01:39, 23.59it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7671/10003 [05:19<02:09, 18.01it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7703/10003 [05:20<02:12, 17.37it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7720/10003 [05:21<02:00, 19.00it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7728/10003 [05:22<02:21, 16.03it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 77%|███████▋  | 7746/10003 [05:23<01:35, 23.58it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 78%|███████▊  | 7776/10003 [05:24<01:24, 26.23it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 78%|███████▊  | 7800/10003 [05:25<01:23, 26.43it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 78%|███████▊  | 7848/10003 [05:26<01:19, 26.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 79%|███████▊  | 7857/10003 [05:27<01:24, 25.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 79%|███████▉  | 7881/10003 [05:28<01:18, 26.93it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 79%|███████▉  | 7926/10003 [05:29<01:17, 26.67it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 79%|███████▉  | 7938/10003 [05:30<01:16, 26.92it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 80%|███████▉  | 7965/10003 [05:31<01:16, 26.51it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 80%|███████▉  | 7986/10003 [05:31<01:14, 26.91it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 80%|████████  | 8024/10003 [05:33<01:45, 18.68it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 80%|████████  | 8041/10003 [05:34<01:41, 19.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 81%|████████  | 8061/10003 [05:35<01:38, 19.73it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 81%|████████  | 8069/10003 [05:36<01:48, 17.82it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 81%|████████  | 8084/10003 [05:37<01:54, 16.75it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 81%|████████▏ | 8129/10003 [05:38<01:15, 24.88it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 82%|████████▏ | 8153/10003 [05:39<01:11, 25.82it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 82%|████████▏ | 8162/10003 [05:40<01:13, 24.92it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 82%|████████▏ | 8186/10003 [05:41<01:08, 26.35it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 82%|████████▏ | 8231/10003 [05:42<01:07, 26.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 82%|████████▏ | 8237/10003 [05:42<01:13, 24.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 83%|████████▎ | 8264/10003 [05:44<01:11, 24.28it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 83%|████████▎ | 8309/10003 [05:45<01:05, 25.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 83%|████████▎ | 8318/10003 [05:46<01:06, 25.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 83%|████████▎ | 8342/10003 [05:47<01:05, 25.39it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 84%|████████▎ | 8373/10003 [05:48<01:31, 17.91it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 84%|████████▍ | 8392/10003 [05:49<01:29, 17.96it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 84%|████████▍ | 8409/10003 [05:50<01:29, 17.78it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 84%|████████▍ | 8417/10003 [05:51<01:34, 16.80it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 84%|████████▍ | 8437/10003 [05:52<01:04, 24.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 85%|████████▍ | 8458/10003 [05:52<01:00, 25.72it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 85%|████████▌ | 8506/10003 [05:54<01:01, 24.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 85%|████████▌ | 8530/10003 [05:55<00:53, 27.29it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 85%|████████▌ | 8539/10003 [05:56<00:56, 25.77it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 86%|████████▌ | 8563/10003 [05:57<00:55, 25.98it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 86%|████████▌ | 8611/10003 [05:58<00:51, 26.91it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 86%|████████▋ | 8635/10003 [05:59<00:52, 26.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 86%|████████▋ | 8644/10003 [06:00<00:55, 24.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 87%|████████▋ | 8668/10003 [06:01<00:53, 24.89it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 87%|████████▋ | 8692/10003 [06:02<01:03, 20.61it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 87%|████████▋ | 8724/10003 [06:03<01:13, 17.49it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 87%|████████▋ | 8743/10003 [06:04<01:05, 19.27it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 88%|████████▊ | 8760/10003 [06:05<01:14, 16.69it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 88%|████████▊ | 8766/10003 [06:06<01:10, 17.46it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 88%|████████▊ | 8789/10003 [06:07<00:51, 23.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 88%|████████▊ | 8816/10003 [06:08<00:44, 26.73it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 88%|████████▊ | 8837/10003 [06:08<00:45, 25.79it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 89%|████████▉ | 8885/10003 [06:10<00:42, 26.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 89%|████████▉ | 8894/10003 [06:11<00:43, 25.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 89%|████████▉ | 8918/10003 [06:12<00:42, 25.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 89%|████████▉ | 8948/10003 [06:13<00:39, 26.77it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 90%|████████▉ | 8972/10003 [06:14<00:38, 26.82it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 90%|█████████ | 9017/10003 [06:15<00:35, 27.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 90%|█████████ | 9041/10003 [06:16<00:45, 21.20it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 91%|█████████ | 9062/10003 [06:17<00:45, 20.47it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 91%|█████████ | 9077/10003 [06:18<00:52, 17.76it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 91%|█████████ | 9085/10003 [06:19<00:51, 17.77it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 91%|█████████ | 9104/10003 [06:20<00:49, 18.30it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 91%|█████████ | 9120/10003 [06:21<00:48, 18.12it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 92%|█████████▏| 9164/10003 [06:22<00:32, 26.00it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 92%|█████████▏| 9173/10003 [06:23<00:32, 25.68it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 92%|█████████▏| 9197/10003 [06:23<00:29, 27.07it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 92%|█████████▏| 9245/10003 [06:25<00:28, 26.58it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 93%|█████████▎| 9254/10003 [06:26<00:28, 25.97it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 93%|█████████▎| 9278/10003 [06:27<00:26, 27.03it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 93%|█████████▎| 9323/10003 [06:28<00:25, 26.25it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 93%|█████████▎| 9335/10003 [06:29<00:25, 26.22it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 94%|█████████▎| 9359/10003 [06:30<00:24, 26.43it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 94%|█████████▍| 9398/10003 [06:31<00:29, 20.83it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 94%|█████████▍| 9407/10003 [06:32<00:29, 20.41it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 94%|█████████▍| 9425/10003 [06:33<00:33, 17.46it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 95%|█████████▍| 9455/10003 [06:34<00:30, 18.21it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 95%|█████████▍| 9472/10003 [06:35<00:29, 18.10it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 95%|█████████▍| 9481/10003 [06:36<00:23, 22.66it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 95%|█████████▌| 9526/10003 [06:37<00:18, 26.37it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 95%|█████████▌| 9535/10003 [06:38<00:18, 25.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 96%|█████████▌| 9562/10003 [06:39<00:17, 25.27it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 96%|█████████▌| 9583/10003 [06:39<00:15, 26.82it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 96%|█████████▋| 9631/10003 [06:41<00:14, 25.81it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 96%|█████████▋| 9640/10003 [06:42<00:13, 25.93it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 97%|█████████▋| 9664/10003 [06:43<00:13, 26.02it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 97%|█████████▋| 9709/10003 [06:44<00:10, 27.24it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 97%|█████████▋| 9718/10003 [06:45<00:10, 26.50it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9757/10003 [06:46<00:12, 20.04it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9772/10003 [06:47<00:14, 15.92it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9786/10003 [06:48<00:14, 14.99it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9792/10003 [06:49<00:14, 14.91it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9808/10003 [06:50<00:12, 15.44it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9822/10003 [06:51<00:11, 15.74it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 98%|█████████▊| 9840/10003 [06:52<00:09, 16.75it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 99%|█████████▊| 9867/10003 [06:53<00:07, 17.19it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 99%|█████████▊| 9873/10003 [06:54<00:07, 17.18it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 99%|█████████▉| 9918/10003 [06:55<00:03, 26.38it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            " 99%|█████████▉| 9942/10003 [06:56<00:02, 26.31it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|█████████▉| 9966/10003 [06:57<00:01, 26.29it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|█████████▉| 9975/10003 [06:58<00:01, 25.92it/s]/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "100%|██████████| 10003/10003 [06:59<00:00, 23.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Once RMSE: 1.039139, Duration: 419.114947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0391391149251126"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_once(test_graphs, model, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmtaEuSRMWL",
        "outputId": "9b272350-9100-4d46-8897-4b78b66e9fc8"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IGMC"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppp = DataLoader(test_graphs, batch_size=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D_uW9gJRm16",
        "outputId": "f37cfc06-53fe-4aa6-eced-e8c44c05d8c6"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_user_recommendations(user_id, model, dataset, adj_matrix, u_features, v_features, class_values, h=1, sample_ratio=1.0, max_nodes_per_hop=100):\n",
        "  \"\"\"\n",
        "  Get movie recommendations for a specific user.\n",
        "\n",
        "  Args:\n",
        "    user_id (int): The original user ID (before mapping).\n",
        "    model: The trained IGMC model.\n",
        "    dataset: The MovieLens dataset object.\n",
        "    adj_matrix (scipy.sparse.csr_matrix): The training adjacency matrix.\n",
        "    u_features (scipy.sparse.csr_matrix): User features matrix.\n",
        "    v_features (scipy.sparse.csr_matrix): Movie features matrix.\n",
        "    class_values (numpy.ndarray): Array of possible rating values.\n",
        "    h (int): Number of hops for subgraph extraction.\n",
        "    sample_ratio (float): Sampling ratio for subgraph nodes.\n",
        "    max_nodes_per_hop (int): Maximum number of nodes per hop.\n",
        "\n",
        "  Returns:\n",
        "    list: A list of recommended movie titles.\n",
        "  \"\"\"\n",
        "  # Map the original user ID to the internal ID used in the model\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  u_nodes_ratings = np.array(data_array)[:, 0].astype(np.int32)\n",
        "  _, u_dict, _ = map_data(u_nodes_ratings)\n",
        "\n",
        "  if user_id not in u_dict:\n",
        "    print(f\"User ID {user_id} not found in the dataset.\")\n",
        "    return []\n",
        "\n",
        "  internal_user_id = u_dict[user_id]\n",
        "\n",
        "  # Get all movies the user has NOT rated\n",
        "  rated_movies = dataset.ratings_df[dataset.ratings_df['u_nodes'] == user_id]['v_nodes'].values.tolist()\n",
        "  all_movie_ids = dataset.movies_df['movie id'].values.tolist()\n",
        "  unrated_movie_ids = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
        "\n",
        "  # Map original unrated movie IDs to internal IDs\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  v_nodes_ratings = np.array(data_array)[:, 1].astype(np.int32)\n",
        "  _, v_dict, _ = map_data(v_nodes_ratings)\n",
        "\n",
        "  internal_unrated_movie_ids = [v_dict[movie_id] for movie_id in unrated_movie_ids if movie_id in v_dict]\n",
        "  original_unrated_movie_ids = [movie_id for movie_id in unrated_movie_ids if movie_id in v_dict] # Keep track of original IDs\n",
        "\n",
        "  if not internal_unrated_movie_ids:\n",
        "    print(f\"User ID {user_id} has rated all movies or no unrated movies found in the dataset.\")\n",
        "    return []\n",
        "\n",
        "  # Create link indices and dummy labels for the unrated movies\n",
        "  links_to_predict = (np.array([internal_user_id] * len(internal_unrated_movie_ids)), np.array(internal_unrated_movie_ids))\n",
        "  dummy_labels = np.zeros(len(internal_unrated_movie_ids), dtype=np.int32) # Labels don't matter for prediction\n",
        "\n",
        "  # Create a dynamic dataset for the links to predict\n",
        "  predict_dataset = MyDynamicDataset(\n",
        "      root='ml-1m/predict',\n",
        "      A=adj_matrix,\n",
        "      links=links_to_predict,\n",
        "      labels=dummy_labels,\n",
        "      h=h,\n",
        "      sample_ratio=sample_ratio,\n",
        "      max_nodes_per_hop=max_nodes_per_hop,\n",
        "      u_features=u_features,\n",
        "      v_features=v_features,\n",
        "      class_values=class_values,\n",
        "      max_num=None\n",
        "  )\n",
        "\n",
        "  predict_loader = DataLoader(test_dataset, batch_size=50, shuffle=False, num_workers=2)\n",
        "\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    for data in predict_loader:\n",
        "      data = data.to(device)\n",
        "      out = model(data)\n",
        "      predictions.extend(out.cpu().numpy())\n",
        "\n",
        "  # Get the predicted ratings and sort movies by predicted rating\n",
        "  predicted_ratings = np.array(predictions)\n",
        "  sorted_movie_indices = np.argsort(predicted_ratings)[::-1] # Descending order\n",
        "\n",
        "  # Get the top N recommended movie original IDs\n",
        "  top_n = 10 # You can adjust this\n",
        "  top_movie_internal_ids = np.array(internal_unrated_movie_ids)[sorted_movie_indices[:top_n]]\n",
        "  top_movie_original_ids = [original_unrated_movie_ids[internal_unrated_movie_ids.index(internal_id)] for internal_id in top_movie_internal_ids]\n",
        "\n",
        "  # Get the movie titles\n",
        "  recommended_movie_titles = dataset.movies_df[dataset.movies_df['movie id'].isin(top_movie_original_ids)]['movie title'].values.tolist()\n",
        "\n",
        "  return recommended_movie_titles\n",
        "\n",
        "# Example usage: Get recommendations for user with original ID 1\n",
        "user_id_to_recommend = 1\n",
        "recommendations = get_user_recommendations(user_id_to_recommend, model, dataset, adj_train, u_features, v_features, class_values)\n",
        "\n",
        "print(f\"Recommendations for user {user_id_to_recommend}:\")\n",
        "for movie_title in recommendations:\n",
        "  print(f\"- {movie_title}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hn_L862ETxMO",
        "outputId": "4afcb043-0466-4531-ab09-a15e229ca6a1"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\", line 291, in __getitem__\n    data = self.get(self.indices()[idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-100-3201907978.py\", line 147, in get\n    return construct_pyg_graph(*tmp)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-100-3201907978.py\", line 294, in construct_pyg_graph\n    data.u_feature = torch.FloatTensor(u_feature).unsqueeze(0)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\", line 425, in __len__\n    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\nTypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-162-1171300972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Example usage: Get recommendations for user with original ID 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0muser_id_to_recommend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id_to_recommend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Recommendations for user {user_id_to_recommend}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-162-1171300972.py\u001b[0m in \u001b[0;36mget_user_recommendations\u001b[0;34m(user_id, model, dataset, adj_matrix, u_features, v_features, class_values, h, sample_ratio, max_nodes_per_hop)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\", line 291, in __getitem__\n    data = self.get(self.indices()[idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-100-3201907978.py\", line 147, in get\n    return construct_pyg_graph(*tmp)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipython-input-100-3201907978.py\", line 294, in construct_pyg_graph\n    data.u_feature = torch.FloatTensor(u_feature).unsqueeze(0)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\", line 425, in __len__\n    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\nTypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuAXESRSaJe_"
      },
      "source": [
        "# Dump and save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1P0DIs1Q27A"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa2c3100",
        "outputId": "3e5bcc5c-fac2-4530-ef6d-cb25d050b04d"
      },
      "source": [
        "# Example usage: Get recommendations for user with original ID 1\n",
        "user_id_to_recommend = 2\n",
        "recommendations = get_user_recommendations(user_id_to_recommend, model, dataset, adj_train, u_features, v_features, class_values)\n",
        "\n",
        "print(f\"Recommendations for user {user_id_to_recommend}:\")\n",
        "for movie_title in recommendations:\n",
        "  print(f\"- {movie_title}\")"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/sparse/_index.py:168: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 2:\n",
            "- 2001: A Space Odyssey (1968)\n",
            "- Fish Called Wanda, A (1988)\n",
            "- Monty Python and the Holy Grail (1974)\n",
            "- Wrong Trousers, The (1993)\n",
            "- Princess Bride, The (1987)\n",
            "- Raiders of the Lost Ark (1981)\n",
            "- Psycho (1960)\n",
            "- Blues Brothers, The (1980)\n",
            "- This Is Spinal Tap (1984)\n",
            "- Close Shave, A (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie1 = dataset.movies_df[dataset.movies_df['movie id'] == 1]"
      ],
      "metadata": {
        "id": "4ZP_HngKWN-j"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get first movie by id and return dict\n",
        "\n",
        "movie1.to_dict('records')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZyZao22W1sp",
        "outputId": "866f1fb5-81bb-4102-a3a2-56047cced830"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie id': 1,\n",
              " 'movie title': 'Toy Story (1995)',\n",
              " 'release date': '01-Jan-1995',\n",
              " 'video release date': nan,\n",
              " 'IMDb URL': 'http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)',\n",
              " 'unknown': 0,\n",
              " 'Action': 0,\n",
              " 'Adventure': 0,\n",
              " 'Animation': 1,\n",
              " 'Childrens': 1,\n",
              " 'Comedy': 1,\n",
              " 'Crime': 0,\n",
              " 'Documentary': 0,\n",
              " 'Drama': 0,\n",
              " 'Fantasy': 0,\n",
              " 'Film-Noir': 0,\n",
              " 'Horror': 0,\n",
              " 'Musical': 0,\n",
              " 'Mystery': 0,\n",
              " 'Romance': 0,\n",
              " 'Sci-Fi': 0,\n",
              " 'Thriller': 0,\n",
              " 'War': 0,\n",
              " 'Western': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4163229d"
      },
      "source": [
        "# Task\n",
        "Explain how to get recommendations using the trained model and necessary data components (`adj_train`, `u_features`, `v_features`) in a new Python environment, assuming these components are not directly available. Provide example Python code to demonstrate the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f9e701e"
      },
      "source": [
        "## Save necessary components\n",
        "\n",
        "### Subtask:\n",
        "Save the trained model, the training adjacency matrix, user features, item features, the MovieLens dataset object, and class values to files using appropriate serialization methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beaca656"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the trained model, adjacency matrix, user features, item features, dataset object, and class values to files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1354c719"
      },
      "source": [
        "import joblib\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'trained_model.pkl')\n",
        "\n",
        "# Save the training adjacency matrix\n",
        "sp.save_npz('adj_train.npz', adj_train)\n",
        "\n",
        "# Save the user features\n",
        "sp.save_npz('u_features.npz', u_features)\n",
        "\n",
        "# Save the item features\n",
        "sp.save_npz('v_features.npz', v_features)\n",
        "\n",
        "# Save the dataset object\n",
        "joblib.dump(dataset, 'dataset.pkl')\n",
        "\n",
        "# Save the class values\n",
        "np.save('class_values.npy', class_values)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1f9b16e"
      },
      "source": [
        "## Load components and get recommendations in a new environment\n",
        "\n",
        "### Subtask:\n",
        "Provide example code demonstrating how to load the saved components in a separate Python script or notebook and then use the `get_user_recommendations` function with these loaded components to get recommendations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cdd55bd"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to provide the example code for loading the saved components and using the `get_user_recommendations` function in a new environment. This involves importing necessary libraries and the custom functions/classes, loading the saved files, defining the recommendation function, and then calling it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba020a80"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to an `IndentationError` in the `SparseColIndexer` class definition. I need to correct the indentation in the `__getitem__` method of this class. I will regenerate the entire code block with the corrected indentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ceUZJaoc3wf",
        "outputId": "237c4bf7-0e35-408b-8359-04f9b02f7b3d"
      },
      "source": [
        "import joblib\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv, RGCNConv, global_sort_pool, global_add_pool\n",
        "from torch_geometric.utils import dropout_adj, dropout_edge\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import multiprocessing as mp\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Define the custom classes and functions from the original notebook\n",
        "def subgraph_extraction_labeling(ind, Arow, Acol, h=1, sample_ratio=1.0,\n",
        "                                 max_nodes_per_hop = None, u_features = None,\n",
        "                                 v_features = None, class_values = None, y =1):\n",
        "  # extract the h-hop enclosing subgraph around link 'ind'\n",
        "  u_nodes, v_nodes = [ind[0]], [ind[1]]\n",
        "  u_dist, v_dist = [0], [0]\n",
        "  u_visited, v_visited = set([ind[0]]), set([ind[1]])\n",
        "  u_fringe, v_fringe = set([ind[0]]), set([ind[1]])\n",
        "  for dist in range(1, h+1):\n",
        "    v_fringe, u_fringe = neighbors(u_fringe, Arow), neighbors(v_fringe, Acol)\n",
        "    u_fringe = u_fringe - u_visited\n",
        "    v_fringe = v_fringe - v_visited\n",
        "    u_visited = u_visited.union(u_fringe)\n",
        "    v_visited = v_visited.union(v_fringe)\n",
        "    if sample_ratio < 1.0:\n",
        "      u_fringe = random.sample(list(u_fringe), int(sample_ratio*len(u_fringe)))\n",
        "      v_fringe = random.sample(list(v_fringe), int(sample_ratio*len(v_fringe)))\n",
        "    if max_nodes_per_hop is not None:\n",
        "      if max_nodes_per_hop < len(u_fringe):\n",
        "        u_fringe = random.sample(list(u_fringe), max_nodes_per_hop)\n",
        "      if max_nodes_per_hop < len(v_fringe):\n",
        "        v_fringe = random.sample(list(v_fringe), max_nodes_per_hop)\n",
        "    if len(u_fringe)  == 0 and len(v_fringe) == 0:\n",
        "      break\n",
        "\n",
        "    u_nodes = u_nodes + list(u_fringe)\n",
        "    v_nodes = v_nodes + list(v_fringe)\n",
        "    u_dist = u_dist + [dist]*len(u_fringe)\n",
        "    v_dist = v_dist + [dist]*len(v_fringe)\n",
        "\n",
        "  subgraph = Arow[u_nodes][:, v_nodes]\n",
        "  # remove link between target nodes\n",
        "  subgraph[0, 0] = 0\n",
        "\n",
        "  # prepare pyg graph constructor input\n",
        "  u, v, r = ssp.find(subgraph) #r is 1, 2,... (rating labels + 1)\n",
        "  v += len(u_nodes)\n",
        "  r = r - 1 # transform r back to rating label\n",
        "  num_nodes = len(u_nodes) + len(v_nodes)\n",
        "  node_labels = [x*2 for x in u_dist] + [x*2+1 for x in v_dist]\n",
        "  max_node_label = 2*h + 1\n",
        "  y = class_values[y]\n",
        "\n",
        "  # get node features\n",
        "  if u_features is not None:\n",
        "    u_features = u_features[u_nodes]\n",
        "  if v_features is not None:\n",
        "    v_features = v_features[v_nodes]\n",
        "  node_features = None\n",
        "\n",
        "  if True:\n",
        "    # only output node features for the target user and item\n",
        "    if u_features is not None and v_features is not None:\n",
        "      # Convert sparse matrices to dense NumPy arrays before returning\n",
        "      node_features = [u_features[0].todense(), v_features[0].todense()]\n",
        "\n",
        "  return u, v, r, node_labels, max_node_label, y, node_features\n",
        "\n",
        "def construct_pyg_graph(u, v, r, node_labels, max_node_label, y, node_features):\n",
        "  u, v = torch.LongTensor(u), torch.LongTensor(v)\n",
        "  r = torch.LongTensor(r)\n",
        "  edge_index = torch.stack([torch.cat([u, v]), torch.cat([v, u])], 0)\n",
        "  edge_type = torch.cat([r, r])\n",
        "  x = torch.FloatTensor(one_hot(node_labels, max_node_label+1))\n",
        "  y = torch.FloatTensor([y])\n",
        "  data = Data(x, edge_index, edge_type = edge_type, y = y)\n",
        "\n",
        "  if node_features is not None:\n",
        "    if type(node_features) == list:\n",
        "      u_feature, v_feature = node_features\n",
        "      data.u_feature = torch.FloatTensor(u_feature).unsqueeze(0)\n",
        "      data.v_feature = torch.FloatTensor(v_feature).unsqueeze(0)\n",
        "    else:\n",
        "      x2 = torch.FloatTensor(node_features)\n",
        "      data.x = torch.cat([data.x, x2], 1)\n",
        "  return data\n",
        "\n",
        "def neighbors(fringe, A):\n",
        "  # find all 1-hop neighbors of nodes in fringe from A\n",
        "  return set(A[list(fringe)].indices)\n",
        "\n",
        "def one_hot(idx, length):\n",
        "  idx = np.array(idx)\n",
        "  x = np.zeros([len(idx), length])\n",
        "  x[np.arange(len(idx)), idx] = 1.0\n",
        "  return x\n",
        "\n",
        "class SparseRowIndexer:\n",
        "  def __init__(self, csr_matrix):\n",
        "    data = []\n",
        "    indices = []\n",
        "    indptr = []\n",
        "\n",
        "    for row_start, row_end in zip(csr_matrix.indptr[:-1], csr_matrix.indptr[1:]):\n",
        "      data.append(csr_matrix.data[row_start:row_end])\n",
        "      indices.append(csr_matrix.indices[row_start:row_end])\n",
        "      indptr.append(row_end - row_start)  #nnz of the row\n",
        "\n",
        "    self.data = np.array(data, dtype = object)\n",
        "    self.indices = np.array(indices, dtype = object)\n",
        "    self.indptr = np.array(indptr, dtype = object)\n",
        "    self.shape = csr_matrix.shape\n",
        "  def __getitem__(self, row_selector):\n",
        "    indices = np.concatenate(self.indices[row_selector])\n",
        "    data = np.concatenate(self.data[row_selector])\n",
        "    indptr = np.append(0, np.cumsum(self.indptr[row_selector]))\n",
        "    shape = [indptr.shape[0] - 1, self.shape[1]]\n",
        "    return ssp.csr_matrix((data, indices, indptr), shape = shape)\n",
        "\n",
        "class SparseColIndexer:\n",
        "  def __init__(self, csc_matrix):\n",
        "    data = []\n",
        "    indices = []\n",
        "    indptr = []\n",
        "\n",
        "    for col_start, col_end in zip(csc_matrix.indptr[:-1], csc_matrix.indptr[1:]):\n",
        "      data.append(csc_matrix.data[col_start:col_end])\n",
        "      indices.append(csc_matrix.data[col_start:col_end])\n",
        "      indptr.append(col_end - col_start)\n",
        "\n",
        "    self.data = np.array(data, dtype = object)\n",
        "    self.indices = np.array(indices, dtype = object)\n",
        "    self.indptr = np.array(indptr, dtype = object)\n",
        "    self.shape = csc_matrix.shape\n",
        "\n",
        "  def __getitem__(self, col_selector):\n",
        "    indices = np.concatenate(self.indices[col_selector])\n",
        "    data = np.concatenate(self.data[col_selector])\n",
        "    indptr = np.append(0, np.cumsum(self.indptr[col_selector]))\n",
        "\n",
        "    shape = [self.shape[0], indptr.shape[0] - 1]\n",
        "    return ssp.csc_matrix((data, indices, indptr), shape = shape)\n",
        "\n",
        "\n",
        "def links2subgraphs(Arow, Acol, links, labels, h=1, sample_ratio = 1.0,\n",
        "                    max_nodes_per_hop = None, u_features = None, v_features = None,\n",
        "                    class_values = None, parallel = True):\n",
        "  # Extract enclosing subgraphs\n",
        "  print('Enclosing subgraph extraction begins...')\n",
        "  g_list = []\n",
        "  if not parallel:\n",
        "    with tqdm(total = len(links[0])) as pbar:\n",
        "      for i, j, g_label in zip(links[0], links[1], labels):\n",
        "        tmp = subgraph_extraction_labeling((i, j), Arow, Acol, h, sample_ratio,\n",
        "                                           max_nodes_per_hop, u_features, v_features,\n",
        "                                           class_values, g_label)\n",
        "        data = construct_pyg_graph(*tmp)\n",
        "        g_list.append(data)\n",
        "        pbar.update(1)\n",
        "  else:\n",
        "    start = time.time()\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    results = pool.starmap_async(\n",
        "        subgraph_extraction_labeling,\n",
        "        [\n",
        "         ((i,j), Arow, Acol, h, sample_ratio, max_nodes_per_hop, u_features,\n",
        "          v_features, class_values, g_label)\n",
        "         for i, j, g_label in zip(links[0], links[1], labels)\n",
        "        ]\n",
        "    )\n",
        "    remaining = results._number_left\n",
        "    pbar = tqdm(total = remaining)\n",
        "    while True:\n",
        "      pbar.update(remaining - results._number_left)\n",
        "      if results.ready(): break\n",
        "      remaining = results._number_left\n",
        "      time.sleep(1)\n",
        "    results = results.get()\n",
        "    pool.close()\n",
        "    pbar.close()\n",
        "    end = time.time()\n",
        "    print(\"Time elapsed for subgraph extraction: {}s\".format(end-start))\n",
        "    print(\"Tranforming to pytorch_geometric graphs...\")\n",
        "    g_list = []\n",
        "    pbar = tqdm(total = len(results))\n",
        "    while results:\n",
        "      tmp = results.pop()\n",
        "      g_list.append(construct_pyg_graph(*tmp))\n",
        "      pbar.update(1)\n",
        "    pbar.close()\n",
        "    end2 = time.time()\n",
        "    print(\"Time elapsed for transforming to pytorch_geometric graphs: {}s\".format(end2-end))\n",
        "  return g_list\n",
        "\n",
        "\n",
        "class MyDynamicDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, A, links, labels, h, sample_ratio, max_nodes_per_hop,\n",
        "                u_features, v_features, class_values, max_num=None):\n",
        "    super(MyDynamicDataset, self).__init__()\n",
        "    self.Arow = SparseRowIndexer(A)\n",
        "    self.Acol = SparseColIndexer(A.tocsc())\n",
        "    self.links = links\n",
        "    self.labels = labels\n",
        "    self.h = h\n",
        "    self.sample_ratio = sample_ratio\n",
        "    self.max_nodes_per_hop = max_nodes_per_hop\n",
        "    self.u_features = u_features\n",
        "    self.v_features = v_features\n",
        "    self.class_values = class_values\n",
        "    if max_num is not None:\n",
        "      np.random.seed(123)\n",
        "      num_links = len(links[0])\n",
        "      perm = np.random.permutation(num_links)\n",
        "      perm = perm[:max_num]\n",
        "      self.links = (links[0][perm], links[1][perm])\n",
        "      self.labels = labels[perm]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.links[0])\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    i, j = self.links[0][idx], self.links[1][idx]\n",
        "    g_label = self.labels[idx]\n",
        "    tmp = subgraph_extraction_labeling(\n",
        "      (i, j), self.Arow, self.Acol, self.h, self.sample_ratio, self.max_nodes_per_hop,\n",
        "      self.u_features, self.v_features, self.class_values, g_label\n",
        "    )\n",
        "    return construct_pyg_graph(*tmp)\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "  # a base GNN class, GCN message passing + sum_pooling\n",
        "  def __init__(self, dataset, gconv = GCNConv, latent_dim=[32, 32, 32, 1],\n",
        "               regression = False, adj_dropout = 0.2,\n",
        "               force_undirected = False):\n",
        "    super(GNN, self).__init__()\n",
        "    self.regression = regression\n",
        "    self.adj_dropout = adj_dropout\n",
        "    self.force_undirected = force_undirected\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(gconv(4, latent_dim[0]))\n",
        "    for i in range(0, len(latent_dim)-1):\n",
        "      self.convs.append(gconv(latent_dim[i], latent_dim[i+1]))\n",
        "    self.lin1 = Linear(sum(latent_dim), 128)\n",
        "    if self.regression:\n",
        "      self.lin2 = Linear(128, 1)\n",
        "    else:\n",
        "      self.lin2 = Linear(128, dataset.num_classes)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "    self.lin1.reset_parameters()\n",
        "    self.lin2.reset_parameters()\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "    if self.adj_dropout > 0:\n",
        "      edge_index, edge_type = dropout_adj(edge_index, edge_type, p=self.adj_dropout,\n",
        "                                          force_undirected=self.force_undirected,\n",
        "                                          num_nodes=len(x), training=self.training\n",
        "        )\n",
        "    concat_states = []\n",
        "    for conv in self.convs:\n",
        "      x = torch.tanh(conv(x, edge_index))\n",
        "      concat_states.append(x)\n",
        "    concat_states = torch.cat(concat_states, 1)\n",
        "    x = global_add_pool(concat_states, batch)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.lin2(x)\n",
        "    if self.regression:\n",
        "      return x[:, 0]\n",
        "    else:\n",
        "      return F.log_softmax(x, dim=-1)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__\n",
        "\n",
        "\n",
        "class IGMC(GNN):\n",
        "  # The GNN model of Inductive Graph-based Matrix Completion.\n",
        "  # Use RGCN convolution + center-nodes readout.\n",
        "  def __init__(self, dataset, gconv=RGCNConv, latent_dim=[32, 32, 32, 32],\n",
        "               num_relations=5, num_bases=2, regression=False, adj_dropout=0.2,\n",
        "               force_undirected=False, side_features=False, n_side_features=0,\n",
        "               multiply_by=1):\n",
        "    super(IGMC, self).__init__(dataset, GCNConv, latent_dim,\n",
        "                               regression, adj_dropout, force_undirected\n",
        "    )\n",
        "    self.multiply_by = multiply_by\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(gconv(4, latent_dim[0], num_relations, num_bases))\n",
        "    for i in range(0, len(latent_dim)-1):\n",
        "      self.convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases))\n",
        "    self.lin1 = Linear(2*sum(latent_dim), 128)\n",
        "    self.side_features = side_features\n",
        "    if side_features:\n",
        "      self.lin1 = Linear(2*sum(latent_dim)+n_side_features, 128)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n",
        "    if self.adj_dropout > 0:\n",
        "      edge_index, edge_mask = dropout_edge(edge_index, p=self.adj_dropout,\n",
        "                                           force_undirected=self.force_undirected,\n",
        "                                           training=self.training)\n",
        "      edge_type = data.edge_type[edge_mask]\n",
        "    concat_states = []\n",
        "    for conv in self.convs:\n",
        "      x = torch.tanh(conv(x, edge_index, edge_type))\n",
        "      concat_states.append(x)\n",
        "    concat_states = torch.cat(concat_states, 1)\n",
        "\n",
        "    users = data.x[:, 0] == 1\n",
        "    items = data.x[:, 1] == 1\n",
        "    x = torch.cat([concat_states[users], concat_states[items]], 1)\n",
        "    if self.side_features:\n",
        "      x = torch.cat([x, data.u_feature, data.v_feature], 1)\n",
        "\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.lin2(x)\n",
        "    if self.regression:\n",
        "      return x[:, 0] * self.multiply_by\n",
        "    else:\n",
        "      return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def map_data(data):\n",
        "  \"\"\"\n",
        "  Map data to proper indices in case they are not in a continues [0,N) range\n",
        "  \"\"\"\n",
        "  uniq = list(set(data))\n",
        "  id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
        "  data = np.array([id_dict[x] for x in data])\n",
        "  n = len(uniq)\n",
        "\n",
        "  return data, id_dict, n\n",
        "\n",
        "# Define the get_user_recommendations function\n",
        "def get_user_recommendations(user_id, model, dataset, adj_matrix, u_features, v_features, class_values, h=1, sample_ratio=1.0, max_nodes_per_hop=100):\n",
        "  \"\"\"\n",
        "  Get movie recommendations for a specific user.\n",
        "\n",
        "  Args:\n",
        "    user_id (int): The original user ID (before mapping).\n",
        "    model: The trained IGMC model.\n",
        "    dataset: The MovieLens dataset object.\n",
        "    adj_matrix (scipy.sparse.csr_matrix): The training adjacency matrix.\n",
        "    u_features (scipy.sparse.csr_matrix): User features matrix.\n",
        "    v_features (scipy.sparse.csr_matrix): Movie features matrix.\n",
        "    class_values (numpy.ndarray): Array of possible rating values.\n",
        "    h (int): Number of hops for subgraph extraction.\n",
        "    sample_ratio (float): Sampling ratio for subgraph nodes.\n",
        "    max_nodes_per_hop (int): Maximum number of nodes per hop.\n",
        "\n",
        "  Returns:\n",
        "    list: A list of recommended movie titles.\n",
        "  \"\"\"\n",
        "  # Map the original user ID to the internal ID used in the model\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  u_nodes_ratings = np.array(data_array)[:, 0].astype(np.int32)\n",
        "  _, u_dict, _ = map_data(u_nodes_ratings)\n",
        "\n",
        "  if user_id not in u_dict:\n",
        "    print(f\"User ID {user_id} not found in the dataset.\")\n",
        "    return []\n",
        "\n",
        "  internal_user_id = u_dict[user_id]\n",
        "\n",
        "  # Get all movies the user has NOT rated\n",
        "  rated_movies = dataset.ratings_df[dataset.ratings_df['u_nodes'] == user_id]['v_nodes'].values.tolist()\n",
        "  all_movie_ids = dataset.movies_df['movie id'].values.tolist()\n",
        "  unrated_movie_ids = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
        "\n",
        "  # Map original unrated movie IDs to internal IDs\n",
        "  data_array = dataset.ratings_df.values.tolist()\n",
        "  v_nodes_ratings = np.array(data_array)[:, 1].astype(np.int32)\n",
        "  _, v_dict, _ = map_data(v_nodes_ratings)\n",
        "\n",
        "  internal_unrated_movie_ids = [v_dict[movie_id] for movie_id in unrated_movie_ids if movie_id in v_dict]\n",
        "  original_unrated_movie_ids = [movie_id for movie_id in unrated_movie_ids if movie_id in v_dict] # Keep track of original IDs\n",
        "\n",
        "\n",
        "  if not internal_unrated_movie_ids:\n",
        "    print(f\"User ID {user_id} has rated all movies or no unrated movies found in the dataset.\")\n",
        "    return []\n",
        "\n",
        "  # Create link indices and dummy labels for the unrated movies\n",
        "  links_to_predict = (np.array([internal_user_id] * len(internal_unrated_movie_ids)), np.array(internal_unrated_movie_ids))\n",
        "  dummy_labels = np.zeros(len(internal_unrated_movie_ids), dtype=np.int32) # Labels don't matter for prediction\n",
        "\n",
        "  # Create a dynamic dataset for the links to predict\n",
        "  # Create a dummy root directory for the dynamic dataset\n",
        "  dummy_root = 'ml-1m/predict_temp'\n",
        "  os.makedirs(dummy_root, exist_ok=True)\n",
        "\n",
        "  predict_dataset = MyDynamicDataset(\n",
        "      root=dummy_root,\n",
        "      A=adj_matrix,\n",
        "      links=links_to_predict,\n",
        "      labels=dummy_labels,\n",
        "      h=h,\n",
        "      sample_ratio=sample_ratio,\n",
        "      max_nodes_per_hop=max_nodes_per_hop,\n",
        "      u_features=u_features,\n",
        "      v_features=v_features,\n",
        "      class_values=class_values,\n",
        "      max_num=None\n",
        "  )\n",
        "\n",
        "  predict_loader = DataLoader(predict_dataset, batch_size=50, shuffle=False, num_workers=2)\n",
        "\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    for data in predict_loader:\n",
        "      data = data.to(device)\n",
        "      out = model(data)\n",
        "      predictions.extend(out.cpu().numpy())\n",
        "\n",
        "  # Get the predicted ratings and sort movies by predicted rating\n",
        "  predicted_ratings = np.array(predictions)\n",
        "  sorted_movie_indices = np.argsort(predicted_ratings)[::-1] # Descending order\n",
        "\n",
        "  # Get the top N recommended movie original IDs\n",
        "  top_n = 10 # You can adjust this\n",
        "  top_movie_internal_ids = np.array(internal_unrated_movie_ids)[sorted_movie_indices[:top_n]]\n",
        "  top_movie_original_ids = [original_unrated_movie_ids[internal_unrated_movie_ids.index(internal_id)] for internal_id in top_movie_internal_ids]\n",
        "\n",
        "  # Get the movie titles\n",
        "  recommended_movie_titles = loaded_dataset.movies_df[loaded_dataset.movies_df['movie id'].isin(top_movie_original_ids)]['movie title'].values.tolist()\n",
        "\n",
        "  return recommended_movie_titles\n",
        "\n",
        "\n",
        "# Load the saved components\n",
        "try:\n",
        "  loaded_model = joblib.load('trained_model.pkl')\n",
        "  loaded_adj_train = sp.load_npz('adj_train.npz')\n",
        "  loaded_u_features = sp.load_npz('u_features.npz')\n",
        "  loaded_v_features = sp.load_npz('v_features.npz')\n",
        "  loaded_dataset = joblib.load('dataset.pkl')\n",
        "  loaded_class_values = np.load('class_values.npy')\n",
        "\n",
        "  # Set the device\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  loaded_model.to(device)\n",
        "\n",
        "  # Example usage: Get recommendations for user with original ID 1\n",
        "  user_id_to_recommend = 1\n",
        "  recommendations = get_user_recommendations(\n",
        "      user_id_to_recommend,\n",
        "      loaded_model,\n",
        "      loaded_dataset,\n",
        "      loaded_adj_train,\n",
        "      loaded_u_features,\n",
        "      loaded_v_features,\n",
        "      loaded_class_values\n",
        "  )\n",
        "\n",
        "  print(f\"Recommendations for user {user_id_to_recommend}:\")\n",
        "  for movie_title in recommendations:\n",
        "    print(f\"- {movie_title}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "  print(f\"Error loading file: {e}. Please ensure all necessary files have been saved.\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 1:\n",
            "- L.A. Confidential (1997)\n",
            "- Close Shave, A (1995)\n",
            "- Trainspotting (1996)\n",
            "- Casablanca (1942)\n",
            "- Maltese Falcon, The (1941)\n",
            "- Sunset Blvd. (1950)\n",
            "- To Catch a Thief (1955)\n",
            "- East of Eden (1955)\n",
            "- Treasure of the Sierra Madre, The (1948)\n",
            "- Big Sleep, The (1946)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea4191f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The trained model (`trained_model.pkl`), training adjacency matrix (`adj_train.npz`), user features (`u_features.npz`), item features (`v_features.npz`), dataset object (`dataset.pkl`), and class values (`class_values.npy`) were successfully saved to disk.\n",
        "*   The necessary custom classes and functions from the original training environment were successfully defined within the new script.\n",
        "*   The saved components were successfully loaded into the new Python environment.\n",
        "*   The `get_user_recommendations` function was successfully used with the loaded components to generate movie recommendations for a specific user (user ID 1).\n",
        "*   The generated recommendations for user ID 1 were successfully printed to the console.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The provided code demonstrates a complete pipeline for saving model and data components and then using them for inference (recommendations) in a separate environment. This process is crucial for deploying trained models.\n",
        "*   For a production environment, consider packaging the necessary code components (classes and functions) into a reusable library or module to avoid redefining them in every inference script.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Q3vPQolzXuic",
        "3uMSZonBeEFJ",
        "xmxTU2VQs0Wm",
        "Ti-zCAhtuAST",
        "YunCQ72h59cD"
      ],
      "provenance": [],
      "mount_file_id": "1qZK7eYqbHjHTpkmqOPZgRMI1GYBVGupu",
      "authorship_tag": "ABX9TyNrVJSZWKSTSlsCjLEmCW3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}